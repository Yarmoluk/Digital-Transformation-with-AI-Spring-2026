# New MicroSim Specifications and Embeds

**Date:** 2026-01-28
**Chapter:** 02-llm-architecture
**Task:** Review chapter for opportunities to add diagrams and MicroSims

---

## Summary

Reviewed Chapter 2 (Large Language Model Architecture) and enhanced it with 5 embedded existing MicroSims and 4 new MicroSim specifications in `<details markdown="1">` blocks.

## Embedded Existing MicroSims (5 iframes added)

| MicroSim | Section | Purpose |
|----------|---------|---------|
| Neural Network Visualization | What Are Large Language Models? | Foundational understanding of forward propagation |
| Autoregressive Generation | Next-Token Prediction Paradigm | Visualize token flow through layers during generation |
| Tokenizer | Tokenization | Interactive exploration of text-to-token conversion |
| Self-Attention Visualization | Self-Attention: Tokens Attending to Tokens | Interactive attention pattern exploration |
| Vector Similarity | Embeddings: Representing Meaning as Numbers | Demonstrate semantic clustering and cosine similarity |

## New MicroSim Specifications (4 `<details>` blocks)

### 1. Multi-Head Attention Comparison
- **Location:** After Multi-Head Attention section (line ~414)
- **Bloom Level:** Analyze (L4)
- **Purpose:** Show how different attention heads focus on different linguistic phenomena (syntactic, semantic, positional, coreference)
- **Key Features:**
  - Grid of 8 attention head visualizations
  - Head specialization labels
  - Aggregate vs individual head views
  - Custom sentence input

### 2. Embedding Dimensions Explorer
- **Location:** After Embeddings section (line ~511)
- **Bloom Level:** Understand (L2)
- **Purpose:** Visualize how embedding dimensions capture semantic features
- **Key Features:**
  - 3D projection of embedding space
  - Dimension feature analysis
  - Vector arithmetic demonstration (king - man + woman = queen)
  - Configurable embedding dimensions (50-1536)

### 3. LLM Scaling Laws Visualization
- **Location:** After Model Parameters section (line ~693)
- **Bloom Level:** Apply (L3)
- **Purpose:** Demonstrate Chinchilla scaling laws for parameters, data, and compute
- **Key Features:**
  - Log-log scaling curves
  - Chinchilla optimal frontier
  - Real model reference points (GPT-3, GPT-4, Claude, Llama)
  - Compute-optimal allocation calculator

### 4. Inference Performance Tradeoffs
- **Location:** After Latency and Throughput section (line ~792)
- **Bloom Level:** Apply (L3)
- **Purpose:** Explore how configuration choices affect inference metrics
- **Key Features:**
  - Model size, batch size, context length sliders
  - TTFT and inter-token latency visualization
  - Quantization effects (FP16, INT8, INT4)
  - KV-cache and speculative decoding toggles
  - Cost-per-token estimates

## Existing Visual Elements (unchanged)

### Mermaid Diagrams (3)
1. Transformer Architecture (flowchart)
2. RLHF Training Pipeline (flowchart)
3. Context Window Management (flowchart + decision tree)

### Existing MicroSim Specifications (2)
1. Tokenization Process Visualization
2. Self-Attention Visualization (detailed spec)

## Metrics

| Metric | Before | After |
|--------|--------|-------|
| Chapter 2 word count | ~5,000 | 6,076 |
| Total site words | 106,970 | 108,432 |
| Embedded MicroSims in Ch2 | 0 | 5 |
| MicroSim specifications in Ch2 | 2 | 6 |
| Total visual elements in Ch2 | 5 | 14 |

## Files Modified

1. `docs/chapters/02-llm-architecture/index.md` - Added embeds and specifications
2. `README.md` - Updated total word count

## Next Steps

The 4 new MicroSim specifications are ready for implementation. Priority order based on educational value:

1. **LLM Scaling Laws** - High business relevance, helps with investment decisions
2. **Inference Performance Tradeoffs** - Practical for deployment planning
3. **Multi-Head Attention Comparison** - Deep technical understanding
4. **Embedding Dimensions Explorer** - Foundational concept visualization

---

*Generated by Claude Code session on 2026-01-28*
