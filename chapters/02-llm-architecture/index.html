
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Technical foundations of transformer-based language models including attention mechanisms, training processes, and key architectural concepts">
      
      
        <meta name="author" content="Daniel Yarmoluk">
      
      
        <link rel="canonical" href="https://yarmoluk.github.io/Digital-Transformation-with-AI-Spring-2026/chapters/02-llm-architecture/">
      
      
        <link rel="prev" href="../01-digital-transformation-ai-foundations/">
      
      
        <link rel="next" href="../03-ai-platform-landscape/">
      
      
        
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>Large Language Model Architecture - Digital Transformation 2.0 with Generative AI</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../css/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config",""),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="custom" data-md-color-accent="orange">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#large-language-model-architecture" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Digital Transformation 2.0 with Generative AI" class="md-header__button md-logo" aria-label="Digital Transformation 2.0 with Generative AI" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Digital Transformation 2.0 with Generative AI
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Large Language Model Architecture
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="custom" data-md-color-accent="orange"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="custom" data-md-color-accent="orange"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/Yarmoluk/Digital-Transformation-with-AI-Spring-2026" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    Digital-Transformation-with-AI-Spring-2026
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../about/" class="md-tabs__link">
        
  
  
    
  
  About

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../course-description/" class="md-tabs__link">
        
  
  
    
  
  Course Description

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
  
    
  
  Chapters

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../learning-graph/" class="md-tabs__link">
          
  
  
    
  
  Learning Graph

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../sims/" class="md-tabs__link">
          
  
  
    
  
  MicroSims

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../glossary/" class="md-tabs__link">
        
  
  
    
  
  Glossary

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../references/" class="md-tabs__link">
        
  
  
    
  
  References

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Digital Transformation 2.0 with Generative AI" class="md-nav__button md-logo" aria-label="Digital Transformation 2.0 with Generative AI" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Digital Transformation 2.0 with Generative AI
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/Yarmoluk/Digital-Transformation-with-AI-Spring-2026" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    Digital-Transformation-with-AI-Spring-2026
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../about/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    About
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../course-description/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Course Description
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
      
        
      
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    Chapters
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4" id="__nav_4_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Chapters
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../01-digital-transformation-ai-foundations/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    1. Digital Transformation and AI Foundations
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    2. Large Language Model Architecture
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    2. Large Language Model Architecture
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      
        Summary
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#concepts-covered" class="md-nav__link">
    <span class="md-ellipsis">
      
        Concepts Covered
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#prerequisites" class="md-nav__link">
    <span class="md-ellipsis">
      
        Prerequisites
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#learning-objectives" class="md-nav__link">
    <span class="md-ellipsis">
      
        Learning Objectives
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Introduction
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#understanding-large-language-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        Understanding Large Language Models
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Understanding Large Language Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-are-large-language-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        What Are Large Language Models?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-next-token-prediction-paradigm" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Next-Token Prediction Paradigm
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tokens-and-tokenization" class="md-nav__link">
    <span class="md-ellipsis">
      
        Tokens and Tokenization
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tokens and Tokenization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#understanding-tokens" class="md-nav__link">
    <span class="md-ellipsis">
      
        Understanding Tokens
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#business-implications-of-tokenization" class="md-nav__link">
    <span class="md-ellipsis">
      
        Business Implications of Tokenization
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-transformer-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Transformer Architecture
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The Transformer Architecture">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#why-transformers-revolutionized-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      
        Why Transformers Revolutionized NLP
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#architecture-overview" class="md-nav__link">
    <span class="md-ellipsis">
      
        Architecture Overview
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-attention-mechanism" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Attention Mechanism
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#self-attention-tokens-attending-to-tokens" class="md-nav__link">
    <span class="md-ellipsis">
      
        Self-Attention: Tokens Attending to Tokens
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-head-attention" class="md-nav__link">
    <span class="md-ellipsis">
      
        Multi-Head Attention
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#embeddings-representing-meaning-as-numbers" class="md-nav__link">
    <span class="md-ellipsis">
      
        Embeddings: Representing Meaning as Numbers
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Embeddings: Representing Meaning as Numbers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-are-embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      
        What Are Embeddings?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#types-of-embeddings-in-llms" class="md-nav__link">
    <span class="md-ellipsis">
      
        Types of Embeddings in LLMs
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-large-language-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        Training Large Language Models
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Training Large Language Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pre-training-learning-from-the-internet" class="md-nav__link">
    <span class="md-ellipsis">
      
        Pre-Training: Learning from the Internet
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fine-tuning-specializing-for-tasks" class="md-nav__link">
    <span class="md-ellipsis">
      
        Fine-Tuning: Specializing for Tasks
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rlhf-aligning-with-human-preferences" class="md-nav__link">
    <span class="md-ellipsis">
      
        RLHF: Aligning with Human Preferences
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-parameters-and-their-effects" class="md-nav__link">
    <span class="md-ellipsis">
      
        Model Parameters and Their Effects
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Model Parameters and Their Effects">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-are-parameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        What Are Parameters?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-running-the-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        Inference: Running the Model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#latency-and-throughput-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      
        Latency and Throughput Optimization
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-context-window" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Context Window
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The Context Window">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-is-a-context-window" class="md-nav__link">
    <span class="md-ellipsis">
      
        What Is a Context Window?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#business-implications-of-context-windows" class="md-nav__link">
    <span class="md-ellipsis">
      
        Business Implications of Context Windows
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#putting-it-all-together" class="md-nav__link">
    <span class="md-ellipsis">
      
        Putting It All Together
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-takeaways" class="md-nav__link">
    <span class="md-ellipsis">
      
        Key Takeaways
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#review-questions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Review Questions
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../03-ai-platform-landscape/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    3. AI Platform Landscape
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../04-prompt-engineering/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    4. Prompt Engineering Fundamentals
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../05-custom-gpts-agents-rag/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    5. Custom GPTs, Agents, and RAG Systems
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../06-llm-api-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    6. LLM API Integration
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../07-multimodal-ai/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    7. Multimodal AI
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../08-governance-ethics-responsible-ai/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    8. AI Governance, Ethics, and Responsible AI
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../09-future-of-work/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    9. Future of Work and Workforce Transformation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../10-business-applications-transformation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    10. Business Applications and AI Transformation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../learning-graph/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    
  
    Learning Graph
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../sims/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    
  
    MicroSims
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../glossary/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Glossary
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../references/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    References
  

    
  </span>
  
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      
        Summary
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#concepts-covered" class="md-nav__link">
    <span class="md-ellipsis">
      
        Concepts Covered
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#prerequisites" class="md-nav__link">
    <span class="md-ellipsis">
      
        Prerequisites
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#learning-objectives" class="md-nav__link">
    <span class="md-ellipsis">
      
        Learning Objectives
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Introduction
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#understanding-large-language-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        Understanding Large Language Models
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Understanding Large Language Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-are-large-language-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        What Are Large Language Models?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-next-token-prediction-paradigm" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Next-Token Prediction Paradigm
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tokens-and-tokenization" class="md-nav__link">
    <span class="md-ellipsis">
      
        Tokens and Tokenization
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tokens and Tokenization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#understanding-tokens" class="md-nav__link">
    <span class="md-ellipsis">
      
        Understanding Tokens
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#business-implications-of-tokenization" class="md-nav__link">
    <span class="md-ellipsis">
      
        Business Implications of Tokenization
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-transformer-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Transformer Architecture
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The Transformer Architecture">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#why-transformers-revolutionized-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      
        Why Transformers Revolutionized NLP
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#architecture-overview" class="md-nav__link">
    <span class="md-ellipsis">
      
        Architecture Overview
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-attention-mechanism" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Attention Mechanism
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#self-attention-tokens-attending-to-tokens" class="md-nav__link">
    <span class="md-ellipsis">
      
        Self-Attention: Tokens Attending to Tokens
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-head-attention" class="md-nav__link">
    <span class="md-ellipsis">
      
        Multi-Head Attention
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#embeddings-representing-meaning-as-numbers" class="md-nav__link">
    <span class="md-ellipsis">
      
        Embeddings: Representing Meaning as Numbers
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Embeddings: Representing Meaning as Numbers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-are-embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      
        What Are Embeddings?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#types-of-embeddings-in-llms" class="md-nav__link">
    <span class="md-ellipsis">
      
        Types of Embeddings in LLMs
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-large-language-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        Training Large Language Models
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Training Large Language Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pre-training-learning-from-the-internet" class="md-nav__link">
    <span class="md-ellipsis">
      
        Pre-Training: Learning from the Internet
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fine-tuning-specializing-for-tasks" class="md-nav__link">
    <span class="md-ellipsis">
      
        Fine-Tuning: Specializing for Tasks
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rlhf-aligning-with-human-preferences" class="md-nav__link">
    <span class="md-ellipsis">
      
        RLHF: Aligning with Human Preferences
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-parameters-and-their-effects" class="md-nav__link">
    <span class="md-ellipsis">
      
        Model Parameters and Their Effects
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Model Parameters and Their Effects">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-are-parameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        What Are Parameters?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-running-the-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        Inference: Running the Model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#latency-and-throughput-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      
        Latency and Throughput Optimization
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-context-window" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Context Window
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The Context Window">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-is-a-context-window" class="md-nav__link">
    <span class="md-ellipsis">
      
        What Is a Context Window?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#business-implications-of-context-windows" class="md-nav__link">
    <span class="md-ellipsis">
      
        Business Implications of Context Windows
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#putting-it-all-together" class="md-nav__link">
    <span class="md-ellipsis">
      
        Putting It All Together
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-takeaways" class="md-nav__link">
    <span class="md-ellipsis">
      
        Key Takeaways
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#review-questions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Review Questions
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
                



  


  <nav class="md-path" aria-label="Navigation" >
    <ol class="md-path__list">
      
        
  
  
    <li class="md-path__item">
      <a href="../.." class="md-path__link">
        
  <span class="md-ellipsis">
    Home
  </span>

      </a>
    </li>
  

      
      
        
  
  
    
    
      <li class="md-path__item">
        <a href="../" class="md-path__link">
          
  <span class="md-ellipsis">
    Chapters
  </span>

        </a>
      </li>
    
  

      
    </ol>
  </nav>

              
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/Yarmoluk/Digital-Transformation-with-AI-Spring-2026/edit/main/docs/chapters/02-llm-architecture/index.md" title="Edit this page" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  


<h1 id="large-language-model-architecture">Large Language Model Architecture<a class="headerlink" href="#large-language-model-architecture" title="Permanent link">&para;</a></h1>
<h2 id="summary">Summary<a class="headerlink" href="#summary" title="Permanent link">&para;</a></h2>
<p>This chapter explores the technical foundations of large language models, explaining how these powerful AI systems work under the hood. Students will learn about transformer architecture, attention mechanisms, and the training processes that enable LLMs to generate human-like text. Understanding these concepts is essential for effectively working with and evaluating AI platforms.</p>
<h2 id="concepts-covered">Concepts Covered<a class="headerlink" href="#concepts-covered" title="Permanent link">&para;</a></h2>
<p>This chapter covers the following 18 concepts from the learning graph:</p>
<ol>
<li>Large Language Models</li>
<li>Transformer Architecture</li>
<li>Attention Mechanism</li>
<li>Self-Attention</li>
<li>Multi-Head Attention</li>
<li>Pre-Training</li>
<li>Fine-Tuning</li>
<li>RLHF</li>
<li>Token</li>
<li>Tokenization</li>
<li>Context Window</li>
<li>Model Parameters</li>
<li>Inference</li>
<li>Latency</li>
<li>Throughput</li>
<li>Embeddings</li>
</ol>
<h2 id="prerequisites">Prerequisites<a class="headerlink" href="#prerequisites" title="Permanent link">&para;</a></h2>
<p>This chapter builds on concepts from:</p>
<ul>
<li><a href="../01-digital-transformation-ai-foundations/">Chapter 1: Digital Transformation and AI Foundations</a></li>
</ul>
<h2 id="learning-objectives">Learning Objectives<a class="headerlink" href="#learning-objectives" title="Permanent link">&para;</a></h2>
<p>After completing this chapter, students will be able to:</p>
<ul>
<li>Explain how large language models generate text through next-token prediction</li>
<li>Describe the transformer architecture and role of attention mechanisms</li>
<li>Understand the training process including pre-training, fine-tuning, and RLHF</li>
<li>Explain tokens, context windows, and their business implications</li>
<li>Interpret model parameters and their effects on performance</li>
</ul>
<hr />
<h2 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Permanent link">&para;</a></h2>
<p>The remarkable capabilities of modern AI assistants—their ability to write poetry, explain complex concepts, generate code, and engage in nuanced conversation—all derive from a common architectural foundation: the <strong>large language model (LLM)</strong>. These systems represent the culmination of decades of research in natural language processing, neural network design, and distributed computing. Yet despite their sophisticated capabilities, LLMs operate according to a deceptively simple objective: predicting the next word in a sequence.</p>
<p>This chapter demystifies the technical machinery underlying LLMs. While business professionals need not understand every mathematical detail, a working knowledge of how these systems function—their architecture, training processes, and operational characteristics—is essential for making informed decisions about AI adoption, evaluating platform capabilities, and anticipating both the possibilities and limitations of generative AI.</p>
<h2 id="understanding-large-language-models">Understanding Large Language Models<a class="headerlink" href="#understanding-large-language-models" title="Permanent link">&para;</a></h2>
<h3 id="what-are-large-language-models">What Are Large Language Models?<a class="headerlink" href="#what-are-large-language-models" title="Permanent link">&para;</a></h3>
<p><strong>Large Language Models (LLMs)</strong> are neural networks trained on massive text corpora to understand and generate human language. The term "large" refers to the number of parameters—the learnable weights that the model adjusts during training. Modern LLMs range from billions to trillions of parameters:</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Organization</th>
<th>Parameters</th>
<th>Release Year</th>
</tr>
</thead>
<tbody>
<tr>
<td>GPT-3</td>
<td>OpenAI</td>
<td>175 billion</td>
<td>2020</td>
</tr>
<tr>
<td>GPT-4</td>
<td>OpenAI</td>
<td>~1.8 trillion (estimated)</td>
<td>2023</td>
</tr>
<tr>
<td>Claude 3.5 Sonnet</td>
<td>Anthropic</td>
<td>Undisclosed</td>
<td>2024</td>
</tr>
<tr>
<td>Gemini Ultra</td>
<td>Google</td>
<td>Undisclosed</td>
<td>2024</td>
</tr>
<tr>
<td>Llama 3.1</td>
<td>Meta</td>
<td>405 billion</td>
<td>2024</td>
</tr>
<tr>
<td>Mixtral 8x22B</td>
<td>Mistral</td>
<td>176 billion (sparse)</td>
<td>2024</td>
</tr>
</tbody>
</table>
<p>At their core, LLMs perform a single task: given a sequence of text, predict the most likely next token. This <strong>next-token prediction</strong> objective, when applied at sufficient scale with appropriate training data, yields systems capable of remarkably sophisticated linguistic behavior.</p>
<p>The fundamental insight is that predicting the next word well requires understanding context, grammar, facts about the world, reasoning patterns, and stylistic conventions. A model that excels at prediction must implicitly learn vast amounts of knowledge about language and the world.</p>
<h3 id="the-next-token-prediction-paradigm">The Next-Token Prediction Paradigm<a class="headerlink" href="#the-next-token-prediction-paradigm" title="Permanent link">&para;</a></h3>
<p>Consider how an LLM generates a response to "The capital of France is":</p>
<ol>
<li>The model receives the input tokens</li>
<li>It processes them through multiple layers of neural network computations</li>
<li>It outputs a probability distribution over its entire vocabulary</li>
<li>The token "Paris" receives high probability</li>
<li>"Paris" is selected and appended to the sequence</li>
<li>The process repeats with "The capital of France is Paris" as input</li>
</ol>
<p>This autoregressive process continues until the model generates a stop token or reaches a maximum length. Each generation step considers all previous context, enabling coherent multi-paragraph outputs.</p>
<div class="admonition note">
<p class="admonition-title">Temperature and Sampling</p>
<p>The selection of the next token need not be deterministic. The <strong>temperature</strong> parameter controls randomness: temperature=0 always selects the highest-probability token, while higher temperatures introduce diversity by making the selection more random. This is why the same prompt can yield different responses.</p>
</div>
<h2 id="tokens-and-tokenization">Tokens and Tokenization<a class="headerlink" href="#tokens-and-tokenization" title="Permanent link">&para;</a></h2>
<h3 id="understanding-tokens">Understanding Tokens<a class="headerlink" href="#understanding-tokens" title="Permanent link">&para;</a></h3>
<p>A <strong>token</strong> is the fundamental unit of text that LLMs process. Contrary to intuition, tokens are neither words nor characters—they are subword units determined by the model's tokenizer. Common words typically map to single tokens, while rare words are split into multiple tokens.</p>
<p>Examples of tokenization (GPT-style):</p>
<table>
<thead>
<tr>
<th>Text</th>
<th>Tokens</th>
<th>Token Count</th>
</tr>
</thead>
<tbody>
<tr>
<td>"Hello"</td>
<td>["Hello"]</td>
<td>1</td>
</tr>
<tr>
<td>"artificial"</td>
<td>["art", "ificial"]</td>
<td>2</td>
</tr>
<tr>
<td>"ChatGPT"</td>
<td>["Chat", "G", "PT"]</td>
<td>3</td>
</tr>
<tr>
<td>"antidisestablishmentarianism"</td>
<td>["ant", "id", "is", "establish", "ment", "arian", "ism"]</td>
<td>7</td>
</tr>
</tbody>
</table>
<p><strong>Tokenization</strong> is the process of converting raw text into token sequences. Different models use different tokenization schemes:</p>
<ul>
<li><strong>Byte Pair Encoding (BPE)</strong>: Used by GPT models. Iteratively merges frequent character pairs to build vocabulary.</li>
<li><strong>WordPiece</strong>: Used by BERT. Similar to BPE but uses likelihood-based merging.</li>
<li><strong>SentencePiece</strong>: Used by Llama and others. Language-agnostic tokenization that works directly on raw text.</li>
</ul>
<h4 id="diagram-tokenization-process-visualization">Diagram: Tokenization Process Visualization<a class="headerlink" href="#diagram-tokenization-process-visualization" title="Permanent link">&para;</a></h4>
<details>
<summary>Tokenization Process Visualization</summary>
<p>Type: microsim</p>
<p>Purpose: Interactive demonstration of how text is converted to tokens and the implications for context window usage</p>
<p>Bloom Taxonomy: Understand (L2) - Explain how tokenization works and affects model behavior</p>
<p>Learning Objective: Students should be able to estimate token counts for different text inputs and understand tokenization implications</p>
<p>Canvas layout (responsive, minimum 800x400px):
- Top section: Text input area
- Middle section: Token visualization
- Bottom section: Statistics and metrics</p>
<p>Visual elements:
- Input text area with character counter
- Token display showing each token as a colored chip
- Token IDs displayed below each chip
- Progress bar showing context window usage</p>
<p>Interactive controls:
- Text input field (multi-line)
- Dropdown: Tokenizer selection (GPT-4, Claude, Llama)
- Button: "Tokenize"
- Toggle: Show/hide token IDs
- Slider: Context window size (4K, 8K, 32K, 128K, 200K)</p>
<p>Display metrics:
- Character count
- Token count
- Tokens per character ratio
- Context window percentage used
- Estimated cost (based on typical pricing)</p>
<p>Behavior:
- As user types, real-time token count updates
- Tokens colored by type (word, subword, punctuation, special)
- Hover over token shows: token text, token ID, frequency in training
- Warning when approaching context limit</p>
<p>Sample texts:
- "Hello, world!"
- Technical paragraph with jargon
- Code snippet
- Non-English text (to show multilingual tokenization differences)</p>
<p>Implementation: p5.js or HTML/JavaScript</p>
</details>
<h3 id="business-implications-of-tokenization">Business Implications of Tokenization<a class="headerlink" href="#business-implications-of-tokenization" title="Permanent link">&para;</a></h3>
<p>Understanding tokens has direct business relevance:</p>
<ul>
<li><strong>Cost calculation</strong>: API pricing is typically per-token (input + output). Efficient prompts reduce costs.</li>
<li><strong>Context limits</strong>: Models have maximum token limits. Long documents may require chunking or summarization.</li>
<li><strong>Language efficiency</strong>: Tokenizers trained primarily on English may require more tokens for other languages, increasing costs.</li>
<li><strong>Code considerations</strong>: Programming languages tokenize differently than natural language, often requiring more tokens.</li>
</ul>
<h2 id="the-transformer-architecture">The Transformer Architecture<a class="headerlink" href="#the-transformer-architecture" title="Permanent link">&para;</a></h2>
<h3 id="why-transformers-revolutionized-nlp">Why Transformers Revolutionized NLP<a class="headerlink" href="#why-transformers-revolutionized-nlp" title="Permanent link">&para;</a></h3>
<p>The <strong>Transformer architecture</strong>, introduced in the 2017 paper "Attention Is All You Need," replaced the sequential processing of recurrent neural networks with parallel attention-based mechanisms. This innovation enabled:</p>
<ul>
<li><strong>Parallel training</strong>: All positions in a sequence can be processed simultaneously</li>
<li><strong>Long-range dependencies</strong>: Direct connections between any two positions regardless of distance</li>
<li><strong>Scalability</strong>: Efficient training on massive datasets using modern GPU clusters</li>
<li><strong>Transfer learning</strong>: Pre-trained transformers adapt effectively to diverse downstream tasks</li>
</ul>
<p>Prior architectures—RNNs and LSTMs—processed sequences one element at a time, creating information bottlenecks and gradient flow problems for long sequences. Transformers eliminated these limitations through the attention mechanism.</p>
<h3 id="architecture-overview">Architecture Overview<a class="headerlink" href="#architecture-overview" title="Permanent link">&para;</a></h3>
<p>A transformer model consists of stacked layers, each containing two primary components:</p>
<ol>
<li><strong>Multi-Head Self-Attention</strong>: Allows each position to attend to all other positions</li>
<li><strong>Feed-Forward Network</strong>: Processes each position independently through dense layers</li>
</ol>
<p>The full architecture includes:</p>
<ul>
<li><strong>Embedding layer</strong>: Converts tokens to dense vector representations</li>
<li><strong>Positional encoding</strong>: Injects sequence position information</li>
<li><strong>N transformer layers</strong>: Each with attention and feed-forward sublayers</li>
<li><strong>Layer normalization</strong>: Stabilizes training</li>
<li><strong>Output projection</strong>: Maps final representations to vocabulary probabilities</li>
</ul>
<h4 id="diagram-transformer-architecture">Diagram: Transformer Architecture<a class="headerlink" href="#diagram-transformer-architecture" title="Permanent link">&para;</a></h4>
<p>The following diagram illustrates the complete transformer architecture, showing how information flows from input tokens through multiple layers to produce output predictions.</p>
<pre class="mermaid"><code>flowchart TB
    subgraph Output["Output Layer"]
        direction TB
        SOFT["Softmax&lt;br/&gt;Probability Distribution"]
        LINEAR["Linear Projection&lt;br/&gt;to Vocabulary"]
    end

    subgraph TL["Transformer Layers (×N)"]
        direction TB
        subgraph Layer["Single Transformer Layer"]
            direction TB
            NORM2["Layer Normalization"]
            FFN["Feed-Forward Network&lt;br/&gt;Linear → ReLU → Linear"]
            ADD2["Add (Residual)"]
            NORM1["Layer Normalization"]
            ATTN["Multi-Head Self-Attention&lt;br/&gt;h parallel attention heads"]
            ADD1["Add (Residual)"]
        end
    end

    subgraph Input["Input Processing"]
        direction TB
        POS["Positional Encoding&lt;br/&gt;Position information"]
        EMB["Token Embeddings&lt;br/&gt;Vocabulary → Vectors"]
        TOK["Input Tokens"]
    end

    TOK --&gt; EMB
    EMB --&gt; POS
    POS --&gt; ADD1
    ADD1 --&gt; ATTN
    ATTN --&gt; NORM1
    NORM1 --&gt; ADD2
    ADD2 --&gt; FFN
    FFN --&gt; NORM2
    NORM2 --&gt; LINEAR
    LINEAR --&gt; SOFT

    %% Residual connections
    POS -.-&gt;|"Residual"| ADD1
    NORM1 -.-&gt;|"Residual"| ADD2

    style Output fill:#E1BEE7,stroke:#7B1FA2,stroke-width:2px
    style TL fill:#C8E6C9,stroke:#388E3C,stroke-width:2px
    style Input fill:#BBDEFB,stroke:#1976D2,stroke-width:2px
    style ATTN fill:#A5D6A7,stroke:#388E3C
    style FFN fill:#FFCC80,stroke:#F57C00</code></pre>
<table>
<thead>
<tr>
<th>Component</th>
<th>Function</th>
<th>Key Innovation</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Token Embeddings</strong></td>
<td>Convert tokens to dense vectors</td>
<td>Learned representations capture meaning</td>
</tr>
<tr>
<td><strong>Positional Encoding</strong></td>
<td>Add position information</td>
<td>Enables parallel processing of sequences</td>
</tr>
<tr>
<td><strong>Multi-Head Attention</strong></td>
<td>Relate all positions to each other</td>
<td>Captures long-range dependencies</td>
</tr>
<tr>
<td><strong>Feed-Forward Network</strong></td>
<td>Transform representations</td>
<td>Adds non-linear processing capacity</td>
</tr>
<tr>
<td><strong>Residual Connections</strong></td>
<td>Bypass around sublayers</td>
<td>Enables training of deep networks</td>
</tr>
<tr>
<td><strong>Layer Normalization</strong></td>
<td>Stabilize activations</td>
<td>Improves training dynamics</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Decoder-Only Architecture</p>
<p>Modern LLMs like GPT use a decoder-only variant where each position can only attend to earlier positions (causal masking). This enables autoregressive generation: predicting one token at a time based on all previous tokens.</p>
</div>
<h3 id="the-attention-mechanism">The Attention Mechanism<a class="headerlink" href="#the-attention-mechanism" title="Permanent link">&para;</a></h3>
<p><strong>Attention</strong> is the core innovation enabling transformers to model relationships between all positions in a sequence. The mechanism computes a weighted combination of values, where weights reflect the relevance of each position to every other position.</p>
<p>The attention computation follows these steps:</p>
<ol>
<li><strong>Project inputs</strong>: Transform each position into Query (Q), Key (K), and Value (V) vectors</li>
<li><strong>Compute attention scores</strong>: Calculate dot product of queries with all keys</li>
<li><strong>Scale</strong>: Divide by square root of dimension to stabilize gradients</li>
<li><strong>Apply softmax</strong>: Convert scores to probability distribution</li>
<li><strong>Weight values</strong>: Multiply values by attention weights and sum</li>
</ol>
<p>The mathematical formulation:</p>
<div class="arithmatex">\[\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V\]</div>
<p>Where <span class="arithmatex">\(d_k\)</span> is the dimension of the key vectors.</p>
<h3 id="self-attention-tokens-attending-to-tokens">Self-Attention: Tokens Attending to Tokens<a class="headerlink" href="#self-attention-tokens-attending-to-tokens" title="Permanent link">&para;</a></h3>
<p><strong>Self-attention</strong> refers to attention where queries, keys, and values all derive from the same sequence. This enables each token to "look at" all other tokens in the input and gather relevant information.</p>
<p>Consider the sentence: "The animal didn't cross the street because it was too tired."</p>
<p>When processing "it," self-attention allows the model to:</p>
<ul>
<li>Attend strongly to "animal" (to resolve the pronoun reference)</li>
<li>Attend to "tired" (which semantically connects to animals, not streets)</li>
<li>Attend to contextual words that disambiguate meaning</li>
</ul>
<p>This mechanism enables sophisticated contextual understanding without explicit programming of linguistic rules.</p>
<h4 id="diagram-self-attention-visualization">Diagram: Self-Attention Visualization<a class="headerlink" href="#diagram-self-attention-visualization" title="Permanent link">&para;</a></h4>
<details>
<summary>Self-Attention Visualization</summary>
<p>Type: microsim</p>
<p>Purpose: Interactive visualization of how tokens attend to other tokens in self-attention</p>
<p>Bloom Taxonomy: Analyze (L4) - Examine attention patterns and their linguistic significance</p>
<p>Learning Objective: Students should be able to interpret attention patterns and understand how context influences token relationships</p>
<p>Canvas layout (responsive, minimum 800x500px):
- Top: Input sentence display with clickable tokens
- Middle: Attention matrix visualization (heatmap)
- Bottom: Selected attention pattern explanation</p>
<p>Visual elements:
- Input tokens as clickable chips arranged horizontally
- Attention matrix as grid with color-coded cells (darker = higher attention)
- Highlighted attention lines connecting selected token to attended tokens
- Attention weight values displayed on hover</p>
<p>Interactive controls:
- Text input field for custom sentences
- Dropdown: Select attention head (1-12)
- Dropdown: Select layer (1-24)
- Toggle: Show attention from → to / to → from
- Button: "Analyze"</p>
<p>Behavior:
- Click any token to highlight its attention pattern
- Attention weights shown as line thickness connecting tokens
- Matrix cells show numerical values on hover
- Side panel explains what the selected head appears to focus on</p>
<p>Sample sentences:
- "The animal didn't cross the street because it was too tired."
- "The bank was closed so I couldn't deposit my check at the river bank."
- "She gave him her book and he gave her his."</p>
<p>Annotations:
- Highlight pronoun resolution patterns
- Show positional attention (adjacent tokens)
- Indicate syntactic attention (subject-verb agreement)</p>
<p>Implementation: p5.js with matrix visualization</p>
</details>
<h3 id="multi-head-attention">Multi-Head Attention<a class="headerlink" href="#multi-head-attention" title="Permanent link">&para;</a></h3>
<p><strong>Multi-head attention</strong> runs multiple attention operations in parallel, each with different learned projections. This allows the model to attend to information from different representation subspaces at different positions.</p>
<p>The multi-head mechanism:</p>
<ol>
<li>Projects Q, K, V into h different subspaces (h = number of heads)</li>
<li>Computes attention in each subspace independently</li>
<li>Concatenates the results</li>
<li>Projects back to original dimension</li>
</ol>
<div class="arithmatex">\[\text{MultiHead}(Q, K, V) = \text{Concat}(\text{head}_1, ..., \text{head}_h)W^O\]</div>
<p>Where each head computes:</p>
<div class="arithmatex">\[\text{head}_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)\]</div>
<p>Different heads learn to focus on different types of relationships:</p>
<table>
<thead>
<tr>
<th>Head Type</th>
<th>Typical Focus</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>Syntactic heads</td>
<td>Subject-verb agreement</td>
<td>"The dogs [run]"</td>
</tr>
<tr>
<td>Positional heads</td>
<td>Adjacent tokens</td>
<td>Local context</td>
</tr>
<tr>
<td>Semantic heads</td>
<td>Related concepts</td>
<td>"doctor" ↔ "patient"</td>
</tr>
<tr>
<td>Coreference heads</td>
<td>Pronoun resolution</td>
<td>"she" ↔ "Maria"</td>
</tr>
</tbody>
</table>
<h2 id="embeddings-representing-meaning-as-numbers">Embeddings: Representing Meaning as Numbers<a class="headerlink" href="#embeddings-representing-meaning-as-numbers" title="Permanent link">&para;</a></h2>
<h3 id="what-are-embeddings">What Are Embeddings?<a class="headerlink" href="#what-are-embeddings" title="Permanent link">&para;</a></h3>
<p><strong>Embeddings</strong> are dense vector representations of tokens (or other discrete entities) in a continuous high-dimensional space. Rather than treating words as arbitrary symbols, embeddings encode semantic relationships through geometric proximity—similar concepts cluster together.</p>
<p>Key properties of embeddings:</p>
<ul>
<li><strong>Dimensionality</strong>: Typically 768 to 4096 dimensions in modern LLMs</li>
<li><strong>Learned representations</strong>: Trained from data, not hand-crafted</li>
<li><strong>Semantic similarity</strong>: Cosine similarity measures conceptual relatedness</li>
<li><strong>Compositionality</strong>: Sentence meanings emerge from token embedding combinations</li>
</ul>
<p>The famous demonstration of embedding arithmetic:</p>
<div class="arithmatex">\[\vec{king} - \vec{man} + \vec{woman} \approx \vec{queen}\]</div>
<p>This suggests embeddings capture semantic relationships that support analogical reasoning.</p>
<h3 id="types-of-embeddings-in-llms">Types of Embeddings in LLMs<a class="headerlink" href="#types-of-embeddings-in-llms" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Embedding Type</th>
<th>Purpose</th>
<th>When Used</th>
</tr>
</thead>
<tbody>
<tr>
<td>Token embeddings</td>
<td>Initial word representation</td>
<td>Input layer</td>
</tr>
<tr>
<td>Position embeddings</td>
<td>Encode sequence order</td>
<td>Added to token embeddings</td>
</tr>
<tr>
<td>Segment embeddings</td>
<td>Distinguish text segments</td>
<td>Some architectures (BERT)</td>
</tr>
<tr>
<td>Output embeddings</td>
<td>Final token representations</td>
<td>Before generation</td>
</tr>
</tbody>
</table>
<div class="admonition tip">
<p class="admonition-title">Business Applications of Embeddings</p>
<p>Embeddings enable powerful applications beyond text generation: semantic search (finding similar documents), clustering (grouping related items), classification (categorizing content), and recommendation systems (suggesting related content). Many organizations extract embeddings from LLMs for these downstream applications.</p>
</div>
<h2 id="training-large-language-models">Training Large Language Models<a class="headerlink" href="#training-large-language-models" title="Permanent link">&para;</a></h2>
<h3 id="pre-training-learning-from-the-internet">Pre-Training: Learning from the Internet<a class="headerlink" href="#pre-training-learning-from-the-internet" title="Permanent link">&para;</a></h3>
<p><strong>Pre-training</strong> is the initial, computationally intensive phase where the model learns from massive text corpora. The objective is typically next-token prediction (for autoregressive models like GPT) or masked language modeling (for bidirectional models like BERT).</p>
<p>Pre-training characteristics:</p>
<ul>
<li><strong>Data scale</strong>: Trillions of tokens from web text, books, code, academic papers</li>
<li><strong>Compute requirements</strong>: Thousands of GPUs for weeks or months</li>
<li><strong>Cost</strong>: Millions of dollars for frontier models</li>
<li><strong>Learning</strong>: Grammar, facts, reasoning patterns, world knowledge</li>
</ul>
<p>The pre-training corpus significantly influences model capabilities. Models trained heavily on code excel at programming tasks; those with extensive scientific literature perform better on technical queries.</p>
<table>
<thead>
<tr>
<th>Training Data Source</th>
<th>What the Model Learns</th>
</tr>
</thead>
<tbody>
<tr>
<td>Web pages</td>
<td>General knowledge, diverse topics</td>
</tr>
<tr>
<td>Books</td>
<td>Long-form reasoning, narrative structure</td>
</tr>
<tr>
<td>Wikipedia</td>
<td>Factual information, structured knowledge</td>
</tr>
<tr>
<td>Academic papers</td>
<td>Technical concepts, citation patterns</td>
</tr>
<tr>
<td>Code repositories</td>
<td>Programming syntax, algorithms</td>
</tr>
<tr>
<td>Social media</td>
<td>Conversational patterns, colloquialisms</td>
</tr>
</tbody>
</table>
<h3 id="fine-tuning-specializing-for-tasks">Fine-Tuning: Specializing for Tasks<a class="headerlink" href="#fine-tuning-specializing-for-tasks" title="Permanent link">&para;</a></h3>
<p><strong>Fine-tuning</strong> adapts a pre-trained model to specific tasks or domains by training on smaller, targeted datasets. This transfer learning approach leverages the general capabilities acquired during pre-training while specializing for particular applications.</p>
<p>Fine-tuning approaches include:</p>
<ul>
<li><strong>Full fine-tuning</strong>: Update all model parameters (resource-intensive)</li>
<li><strong>Parameter-efficient fine-tuning (PEFT)</strong>: Update only a subset of parameters</li>
<li><strong>LoRA (Low-Rank Adaptation)</strong>: Add small trainable matrices to existing weights</li>
<li><strong>Prompt tuning</strong>: Learn only soft prompt embeddings, freeze model weights</li>
</ul>
<p>Fine-tuning enables:</p>
<ul>
<li>Domain adaptation (legal, medical, financial language)</li>
<li>Task specialization (summarization, translation, Q&amp;A)</li>
<li>Style alignment (formal vs. casual, brand voice)</li>
<li>Safety improvements (reducing harmful outputs)</li>
</ul>
<h3 id="rlhf-aligning-with-human-preferences">RLHF: Aligning with Human Preferences<a class="headerlink" href="#rlhf-aligning-with-human-preferences" title="Permanent link">&para;</a></h3>
<p><strong>Reinforcement Learning from Human Feedback (RLHF)</strong> is a training methodology that aligns model outputs with human values and preferences. This technique proved crucial for making ChatGPT helpful, harmless, and honest—transforming a raw language model into an effective AI assistant.</p>
<p>The RLHF process:</p>
<ol>
<li><strong>Supervised fine-tuning</strong>: Train on high-quality human demonstrations of desired behavior</li>
<li><strong>Reward model training</strong>: Train a separate model to predict human preference rankings</li>
<li><strong>Policy optimization</strong>: Use reinforcement learning (typically PPO) to maximize the reward model's score while maintaining output diversity</li>
</ol>
<h4 id="diagram-rlhf-training-pipeline">Diagram: RLHF Training Pipeline<a class="headerlink" href="#diagram-rlhf-training-pipeline" title="Permanent link">&para;</a></h4>
<pre class="mermaid"><code>flowchart LR
    subgraph Stage1["Stage 1: Supervised Fine-Tuning"]
        A[Pre-trained LLM] --&gt; B[SFT Training]
        C[Human Demonstrations] --&gt; B
        B --&gt; D[SFT Model]
    end

    subgraph Stage2["Stage 2: Reward Model Training"]
        D --&gt; E[Generate Outputs]
        E --&gt; F[Human Rankings]
        F --&gt; G[Train Reward Model]
        G --&gt; H[Reward Model]
    end

    subgraph Stage3["Stage 3: Policy Optimization"]
        D --&gt; I[PPO Training]
        H --&gt; I
        I --&gt; J[RLHF Model]
    end

    J -.-&gt;|Iterative Improvement| C

    style Stage1 fill:#e3f2fd
    style Stage2 fill:#fff3e0
    style Stage3 fill:#e8f5e9</code></pre>
<p><strong>RLHF Stage Summary:</strong></p>
<table>
<thead>
<tr>
<th>Stage</th>
<th>Human Involvement</th>
<th>Input</th>
<th>Output</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>1. SFT</strong></td>
<td>High (write ideal responses)</td>
<td>Pre-trained LLM + demos</td>
<td>SFT Model</td>
</tr>
<tr>
<td><strong>2. Reward</strong></td>
<td>Medium (rank outputs)</td>
<td>SFT outputs + rankings</td>
<td>Reward Model</td>
</tr>
<tr>
<td><strong>3. PPO</strong></td>
<td>None (automated)</td>
<td>SFT Model + Reward Model</td>
<td>Aligned Model</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Key Insight</p>
<p>Human annotation is the bottleneck. Stage 3 (PPO) runs automatically once the reward model is trained, allowing continuous improvement without additional human labeling.</p>
</div>
<p>RLHF addresses limitations of pure pre-training:</p>
<ul>
<li><strong>Helpfulness</strong>: Models learn to provide useful, actionable responses</li>
<li><strong>Honesty</strong>: Models learn to acknowledge uncertainty rather than confabulate</li>
<li><strong>Harmlessness</strong>: Models learn to refuse harmful requests</li>
<li><strong>Format compliance</strong>: Models learn to follow instructions about output format</li>
</ul>
<h2 id="model-parameters-and-their-effects">Model Parameters and Their Effects<a class="headerlink" href="#model-parameters-and-their-effects" title="Permanent link">&para;</a></h2>
<h3 id="what-are-parameters">What Are Parameters?<a class="headerlink" href="#what-are-parameters" title="Permanent link">&para;</a></h3>
<p><strong>Model parameters</strong> are the learnable numerical values (weights and biases) that define a neural network's behavior. During training, these values are adjusted to minimize prediction error. During inference, they remain fixed and determine how inputs are transformed to outputs.</p>
<p>Parameter count correlates roughly with model capability, but the relationship is not linear:</p>
<ul>
<li>More parameters → more capacity to store knowledge and patterns</li>
<li>More parameters → better generalization to novel inputs</li>
<li>More parameters → higher computational cost for training and inference</li>
<li>More parameters → greater risk of memorization vs. generalization</li>
</ul>
<p>The scaling laws observed in LLM research suggest that performance improves predictably with increases in parameters, training data, and compute, though with diminishing returns at the frontier.</p>
<h3 id="inference-running-the-model">Inference: Running the Model<a class="headerlink" href="#inference-running-the-model" title="Permanent link">&para;</a></h3>
<p><strong>Inference</strong> is the process of using a trained model to generate outputs for new inputs. Unlike training (which updates parameters), inference uses fixed parameters to transform inputs through the network.</p>
<p>Inference considerations include:</p>
<ul>
<li><strong>Latency</strong>: Time from input to first output token</li>
<li><strong>Throughput</strong>: Tokens generated per second</li>
<li><strong>Memory footprint</strong>: GPU memory required to load the model</li>
<li><strong>Cost</strong>: Computational expense per token</li>
</ul>
<p>The autoregressive nature of LLM inference means each output token requires a full forward pass through the network. This creates a fundamental tension between response length and speed.</p>
<table>
<thead>
<tr>
<th>Factor</th>
<th>Effect on Latency</th>
<th>Effect on Throughput</th>
</tr>
</thead>
<tbody>
<tr>
<td>More parameters</td>
<td>↑ Higher</td>
<td>↓ Lower</td>
</tr>
<tr>
<td>Longer context</td>
<td>↑ Higher</td>
<td>↓ Lower</td>
</tr>
<tr>
<td>Longer output</td>
<td>↑ Higher (cumulative)</td>
<td>Unchanged per token</td>
</tr>
<tr>
<td>Batch size</td>
<td>Minimal per request</td>
<td>↑ Higher aggregate</td>
</tr>
<tr>
<td>Quantization</td>
<td>↓ Lower</td>
<td>↑ Higher</td>
</tr>
</tbody>
</table>
<h3 id="latency-and-throughput-optimization">Latency and Throughput Optimization<a class="headerlink" href="#latency-and-throughput-optimization" title="Permanent link">&para;</a></h3>
<p><strong>Latency</strong>—the time to generate a response—matters for interactive applications. Users perceive delays beyond 100-200ms as sluggish. LLM latency has multiple components:</p>
<ul>
<li><strong>Time to first token (TTFT)</strong>: Processing the input and generating the first output token</li>
<li><strong>Inter-token latency</strong>: Time between subsequent tokens</li>
<li><strong>Total response time</strong>: Cumulative time for complete response</li>
</ul>
<p><strong>Throughput</strong>—tokens generated per unit time—matters for batch processing and cost optimization. Techniques for improving throughput include:</p>
<ul>
<li><strong>Batching</strong>: Processing multiple requests simultaneously</li>
<li><strong>KV-caching</strong>: Storing key-value computations to avoid recomputation</li>
<li><strong>Speculative decoding</strong>: Generating multiple tokens in parallel with verification</li>
<li><strong>Model parallelism</strong>: Distributing the model across multiple GPUs</li>
</ul>
<h2 id="the-context-window">The Context Window<a class="headerlink" href="#the-context-window" title="Permanent link">&para;</a></h2>
<h3 id="what-is-a-context-window">What Is a Context Window?<a class="headerlink" href="#what-is-a-context-window" title="Permanent link">&para;</a></h3>
<p>The <strong>context window</strong> is the maximum number of tokens a model can process in a single forward pass—including both input and output tokens. This limit is architectural, determined by positional encoding schemes and attention computation memory requirements.</p>
<p>Context window sizes have grown dramatically:</p>
<table>
<thead>
<tr>
<th>Model Generation</th>
<th>Typical Context Window</th>
</tr>
</thead>
<tbody>
<tr>
<td>GPT-3 (2020)</td>
<td>4,096 tokens</td>
</tr>
<tr>
<td>GPT-4 (2023)</td>
<td>8,192 / 32,768 tokens</td>
</tr>
<tr>
<td>Claude 3 (2024)</td>
<td>200,000 tokens</td>
</tr>
<tr>
<td>Gemini 1.5 Pro (2024)</td>
<td>1,000,000 tokens</td>
</tr>
</tbody>
</table>
<p>A context window of 200,000 tokens accommodates approximately:</p>
<ul>
<li>150,000 words of English text</li>
<li>A 500-page book</li>
<li>Multiple lengthy documents for comparison</li>
<li>Extended multi-turn conversations</li>
</ul>
<h3 id="business-implications-of-context-windows">Business Implications of Context Windows<a class="headerlink" href="#business-implications-of-context-windows" title="Permanent link">&para;</a></h3>
<p>Context window size directly affects application architecture:</p>
<table>
<thead>
<tr>
<th>Use Case</th>
<th>Context Requirement</th>
<th>Architectural Approach</th>
</tr>
</thead>
<tbody>
<tr>
<td>Simple Q&amp;A</td>
<td>~1,000 tokens</td>
<td>Direct prompting</td>
</tr>
<tr>
<td>Document summarization</td>
<td>10,000-50,000 tokens</td>
<td>Single-pass with large context</td>
</tr>
<tr>
<td>Book analysis</td>
<td>100,000+ tokens</td>
<td>Large context or chunking + synthesis</td>
</tr>
<tr>
<td>Knowledge base queries</td>
<td>Variable</td>
<td>RAG (Retrieval-Augmented Generation)</td>
</tr>
<tr>
<td>Extended conversations</td>
<td>Cumulative</td>
<td>Context management, summarization</td>
</tr>
</tbody>
</table>
<div class="admonition warning">
<p class="admonition-title">Context Window Costs</p>
<p>Larger context windows increase computational cost. Processing 100,000 tokens costs substantially more than processing 1,000 tokens. Design applications to use appropriate context sizes, not maximum available.</p>
</div>
<h4 id="diagram-context-window-management">Diagram: Context Window Management<a class="headerlink" href="#diagram-context-window-management" title="Permanent link">&para;</a></h4>
<p>The following diagram compares four strategies for managing context window limitations, each suited to different scenarios and requirements.</p>
<pre class="mermaid"><code>flowchart LR
    subgraph S1["📝 Strategy 1: Direct Prompting"]
        direction TB
        D1A["Short Query"] --&gt; D1B["LLM"] --&gt; D1C["Response"]
    end

    subgraph S2["✂️ Strategy 2: Chunking + Synthesis"]
        direction TB
        D2A["Long Doc"]
        D2B["Chunk 1"]
        D2C["Chunk 2"]
        D2D["Chunk 3"]
        D2E["Synthesize"]
        D2A --&gt; D2B &amp; D2C &amp; D2D
        D2B &amp; D2C &amp; D2D --&gt; D2E
    end

    subgraph S3["🔍 Strategy 3: RAG"]
        direction TB
        D3A["Query"] --&gt; D3B["Retrieve"]
        D3B --&gt; D3C["Top K Chunks"]
        D3C --&gt; D3D["Generate"]
    end

    subgraph S4["📚 Strategy 4: Full Context"]
        direction TB
        D4A["Entire Document&lt;br/&gt;in Context"] --&gt; D4B["LLM"] --&gt; D4C["Response"]
    end

    style S1 fill:#E3F2FD,stroke:#1565C0,stroke-width:2px
    style S2 fill:#E8F5E9,stroke:#388E3C,stroke-width:2px
    style S3 fill:#FFF3E0,stroke:#F57C00,stroke-width:2px
    style S4 fill:#F3E5F5,stroke:#7B1FA2,stroke-width:2px</code></pre>
<table>
<thead>
<tr>
<th>Strategy</th>
<th>Context Usage</th>
<th>Best For</th>
<th>Pros</th>
<th>Cons</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Direct Prompting</strong></td>
<td>Low (100s of tokens)</td>
<td>Simple queries, short conversations</td>
<td>Fast, cheap, simple</td>
<td>Limited context, no external knowledge</td>
</tr>
<tr>
<td><strong>Chunking + Synthesis</strong></td>
<td>Medium per chunk</td>
<td>Long documents exceeding context</td>
<td>Handles any length</td>
<td>May lose cross-chunk relationships</td>
</tr>
<tr>
<td><strong>RAG</strong></td>
<td>Moderate</td>
<td>Large knowledge bases, specific queries</td>
<td>Scalable, current info, efficient</td>
<td>Retrieval quality critical</td>
</tr>
<tr>
<td><strong>Full Context</strong></td>
<td>High</td>
<td>Complete document understanding</td>
<td>No information loss, holistic</td>
<td>Expensive, slower, still has limits</td>
</tr>
</tbody>
</table>
<p><strong>Decision Tree for Strategy Selection:</strong></p>
<pre class="mermaid"><code>flowchart TD
    Q1{"Does content fit&lt;br/&gt;in context window?"}
    Q2{"Need complete&lt;br/&gt;document understanding?"}
    Q3{"Large knowledge base&lt;br/&gt;with specific queries?"}
    Q4{"Document too long&lt;br/&gt;for context?"}

    Q1 --&gt;|Yes| Q2
    Q1 --&gt;|No| Q4
    Q2 --&gt;|Yes| A1["Full Context"]
    Q2 --&gt;|No| Q3
    Q3 --&gt;|Yes| A2["RAG"]
    Q3 --&gt;|No| A3["Direct Prompting"]
    Q4 --&gt;|Yes| A4["Chunking + Synthesis"]
    Q4 --&gt;|No| A2

    style A1 fill:#F3E5F5,stroke:#7B1FA2
    style A2 fill:#FFF3E0,stroke:#F57C00
    style A3 fill:#E3F2FD,stroke:#1565C0
    style A4 fill:#E8F5E9,stroke:#388E3C</code></pre>
<div class="admonition tip">
<p class="admonition-title">Cost Optimization</p>
<p>Start with the simplest strategy that meets your needs. Direct prompting costs pennies; full context on a 100K document can cost dollars per request. Match strategy complexity to actual requirements.</p>
</div>
<h2 id="putting-it-all-together">Putting It All Together<a class="headerlink" href="#putting-it-all-together" title="Permanent link">&para;</a></h2>
<p>The architectural components covered in this chapter work together to enable LLM capabilities:</p>
<ol>
<li><strong>Tokenization</strong> converts text to numerical representations the model can process</li>
<li><strong>Embeddings</strong> map tokens to dense vectors capturing semantic meaning</li>
<li><strong>Self-attention</strong> enables each position to gather information from all other positions</li>
<li><strong>Multi-head attention</strong> allows simultaneous focus on different relationship types</li>
<li><strong>Transformer layers</strong> stack to build progressively abstract representations</li>
<li><strong>Pre-training</strong> instills broad language knowledge and world understanding</li>
<li><strong>Fine-tuning</strong> specializes the model for particular tasks or domains</li>
<li><strong>RLHF</strong> aligns outputs with human preferences and values</li>
<li><strong>Inference</strong> applies the trained parameters to generate responses</li>
<li><strong>Context windows</strong> bound the information available for each generation</li>
</ol>
<p>Understanding these components enables informed evaluation of LLM capabilities, realistic expectation setting, and effective application design.</p>
<h2 id="key-takeaways">Key Takeaways<a class="headerlink" href="#key-takeaways" title="Permanent link">&para;</a></h2>
<ul>
<li><strong>LLMs predict the next token</strong> based on all preceding context, with sophisticated language capabilities emerging from this simple objective at scale</li>
<li><strong>Tokens are subword units</strong> determined by the tokenizer; understanding tokenization is essential for cost estimation and context management</li>
<li><strong>The transformer architecture</strong> replaced sequential processing with parallel attention, enabling efficient training on massive datasets</li>
<li><strong>Self-attention</strong> allows each token to attend to all other tokens, capturing long-range dependencies and contextual relationships</li>
<li><strong>Multi-head attention</strong> enables simultaneous focus on different relationship types (syntactic, semantic, positional)</li>
<li><strong>Embeddings</strong> represent tokens as dense vectors where semantic similarity corresponds to geometric proximity</li>
<li><strong>Pre-training</strong> teaches broad language knowledge; <strong>fine-tuning</strong> specializes for tasks; <strong>RLHF</strong> aligns with human preferences</li>
<li><strong>Context windows</strong> limit the tokens available for processing; larger windows enable more comprehensive understanding but increase cost</li>
<li><strong>Inference characteristics</strong> (latency, throughput) depend on model size, context length, and optimization techniques</li>
</ul>
<hr />
<h2 id="review-questions">Review Questions<a class="headerlink" href="#review-questions" title="Permanent link">&para;</a></h2>
<details class="question">
<summary>Explain why the attention mechanism was a breakthrough for NLP compared to recurrent architectures.</summary>
<p>Recurrent architectures (RNNs, LSTMs) process sequences one element at a time, creating information bottlenecks as context must pass through each step sequentially. This causes: (1) Gradient vanishing/exploding over long sequences, (2) Difficulty capturing long-range dependencies, (3) Sequential processing preventing parallelization. Attention mechanisms allow direct connections between any two positions regardless of distance, enabling: (1) Parallel processing of all positions simultaneously, (2) Direct modeling of long-range relationships, (3) Efficient training on modern GPU clusters. These advantages enabled training on much larger datasets and longer sequences.</p>
</details>
<details class="question">
<summary>How does RLHF differ from standard supervised fine-tuning, and why is it necessary?</summary>
<p>Supervised fine-tuning trains on human-written examples, teaching the model to imitate demonstrations. RLHF goes further by: (1) Training a reward model to predict human preferences between outputs, (2) Using reinforcement learning to optimize for reward model scores. This is necessary because: (1) Writing perfect demonstrations is expensive and limited, (2) Humans are better at comparing outputs than generating ideal ones, (3) RLHF can optimize for implicit preferences difficult to demonstrate (helpfulness, safety, format). The result is models that better align with what users actually want.</p>
</details>
<details class="question">
<summary>A 100,000-token document needs analysis. Compare using a large-context model versus RAG approach.</summary>
<p><strong>Large-context approach</strong>: Load entire document into context window; model has complete information for holistic analysis; best for tasks requiring understanding relationships across the full document; higher cost per query; works well when full context is consistently needed.</p>
<p><strong>RAG approach</strong>: Index document, retrieve relevant chunks per query; efficient for specific questions; lower per-query cost; scales to unlimited document sizes; may miss cross-section relationships; requires quality retrieval system; better when queries target specific information rather than full-document synthesis.</p>
<p>Choose large-context for comprehensive analysis (summarization, theme extraction); choose RAG for question-answering over large corpora or when cost matters for many queries.</p>
</details>







  
  



  



  <form class="md-feedback" name="feedback" hidden>
    <fieldset>
      <legend class="md-feedback__title">
        Was this page helpful?
      </legend>
      <div class="md-feedback__inner">
        <div class="md-feedback__list">
          
            <button class="md-feedback__icon md-icon" type="submit" title="This page was helpful" data-md-value="1">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 12a8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8 8 8 0 0 0 8-8m2 0a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10M10 9.5c0 .8-.7 1.5-1.5 1.5S7 10.3 7 9.5 7.7 8 8.5 8s1.5.7 1.5 1.5m7 0c0 .8-.7 1.5-1.5 1.5S14 10.3 14 9.5 14.7 8 15.5 8s1.5.7 1.5 1.5m-5 7.73c-1.75 0-3.29-.73-4.19-1.81L9.23 14c.45.72 1.52 1.23 2.77 1.23s2.32-.51 2.77-1.23l1.42 1.42c-.9 1.08-2.44 1.81-4.19 1.81"/></svg>
            </button>
          
            <button class="md-feedback__icon md-icon" type="submit" title="This page could be improved" data-md-value="0">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 12a8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8 8 8 0 0 0 8-8m2 0a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10m-6.5-4c.8 0 1.5.7 1.5 1.5s-.7 1.5-1.5 1.5-1.5-.7-1.5-1.5.7-1.5 1.5-1.5M10 9.5c0 .8-.7 1.5-1.5 1.5S7 10.3 7 9.5 7.7 8 8.5 8s1.5.7 1.5 1.5m2 4.5c1.75 0 3.29.72 4.19 1.81l-1.42 1.42C14.32 16.5 13.25 16 12 16s-2.32.5-2.77 1.23l-1.42-1.42C8.71 14.72 10.25 14 12 14"/></svg>
            </button>
          
        </div>
        <div class="md-feedback__note">
          
            <div data-md-value="1" hidden>
              
              
                
              
              
              
                
                
              
              Thanks for your feedback!
            </div>
          
            <div data-md-value="0" hidden>
              
              
                
              
              
              
                
                
              
              Thanks for your feedback!
            </div>
          
        </div>
      </div>
    </fieldset>
  </form>


                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../01-digital-transformation-ai-foundations/" class="md-footer__link md-footer__link--prev" aria-label="Previous: 1. Digital Transformation and AI Foundations">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                1. Digital Transformation and AI Foundations
              </div>
            </div>
          </a>
        
        
          
          <a href="../03-ai-platform-landscape/" class="md-footer__link md-footer__link--next" aria-label="Next: 3. AI Platform Landscape">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                3. AI Platform Landscape
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2026 Daniel Yarmoluk - University of St. Thomas
    </div>
  
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/Yarmoluk/Digital-Transformation-with-AI-Spring-2026" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://linkedin.com" target="_blank" rel="noopener" title="linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["content.code.copy", "content.action.edit", "navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.expand", "navigation.path", "navigation.prune", "navigation.indexes", "navigation.top", "navigation.footer", "navigation.instant", "navigation.instant.progress", "toc.follow", "search.suggest", "search.highlight", "announce.dismiss", "header.autohide"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
    
  </body>
</html>