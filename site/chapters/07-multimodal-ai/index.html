
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="AI capabilities beyond text including image generation, vision analysis, audio processing, and emerging video technologies">
      
      
        <meta name="author" content="Daniel Yarmoluk">
      
      
        <link rel="canonical" href="https://yarmoluk.github.io/Digital-Transformation-with-AI-Spring-2026/chapters/07-multimodal-ai/">
      
      
        <link rel="prev" href="../../quizzes/quiz-06/">
      
      
        <link rel="next" href="../../quizzes/quiz-07/">
      
      
      <link rel="icon" href="../../img/favicon.svg">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.43">
    
    
      
        <title>Multimodal AI - SEIS 666</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.0253249f.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../css/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-H5EG7E1BQG"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-H5EG7E1BQG",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-H5EG7E1BQG",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
      
        <meta  property="og:type"  content="website" >
      
        <meta  property="og:title"  content="Multimodal AI - SEIS 666" >
      
        <meta  property="og:description"  content="AI capabilities beyond text including image generation, vision analysis, audio processing, and emerging video technologies" >
      
        <meta  property="og:image"  content="https://yarmoluk.github.io/Digital-Transformation-with-AI-Spring-2026/assets/images/social/chapters/07-multimodal-ai/index.png" >
      
        <meta  property="og:image:type"  content="image/png" >
      
        <meta  property="og:image:width"  content="1200" >
      
        <meta  property="og:image:height"  content="630" >
      
        <meta  property="og:url"  content="https://yarmoluk.github.io/Digital-Transformation-with-AI-Spring-2026/chapters/07-multimodal-ai/" >
      
        <meta  name="twitter:card"  content="summary_large_image" >
      
        <meta  name="twitter:title"  content="Multimodal AI - SEIS 666" >
      
        <meta  name="twitter:description"  content="AI capabilities beyond text including image generation, vision analysis, audio processing, and emerging video technologies" >
      
        <meta  name="twitter:image"  content="https://yarmoluk.github.io/Digital-Transformation-with-AI-Spring-2026/assets/images/social/chapters/07-multimodal-ai/index.png" >
      
    
    
  
    
    
    
  

  
    
  

  <!-- Open Graph / Social Media Meta Tags -->
  <meta property="og:type" content="website">
  <meta property="og:title" content="Multimodal AI">
  <meta property="og:description" content="AI capabilities beyond text including image generation, vision analysis, audio processing, and emerging video technologies">
  <meta property="og:image" content="https://yarmoluk.github.io/Digital-Transformation-with-AI-Spring-2026/img/social-card.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  
  <meta property="og:url" content="https://yarmoluk.github.io/Digital-Transformation-with-AI-Spring-2026/chapters/07-multimodal-ai/">
  

  <!-- Twitter Card -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Multimodal AI">
  <meta name="twitter:description" content="AI capabilities beyond text including image generation, vision analysis, audio processing, and emerging video technologies">
  <meta name="twitter:image" content="https://yarmoluk.github.io/Digital-Transformation-with-AI-Spring-2026/img/social-card.png">

  <!-- Author -->
  <meta name="author" content="Daniel R. Yarmoluk">

  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="custom" data-md-color-accent="orange">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#multimodal-ai" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="SEIS 666" class="md-header__button md-logo" aria-label="SEIS 666" data-md-component="logo">
      
  <img src="../../img/favicon.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            SEIS 666
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Multimodal AI
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="custom" data-md-color-accent="orange"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="custom" data-md-color-accent="orange"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/Yarmoluk/Digital-Transformation-with-AI-Spring-2026" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    Link to GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="SEIS 666" class="md-nav__button md-logo" aria-label="SEIS 666" data-md-component="logo">
      
  <img src="../../img/favicon.svg" alt="logo">

    </a>
    SEIS 666
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/Yarmoluk/Digital-Transformation-with-AI-Spring-2026" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    Link to GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../about/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    About
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../course-description/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Course Description
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Chapters
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4" id="__nav_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Chapters
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../01-digital-transformation-ai-foundations/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    1. Digital Transformation and AI Foundations
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../02-llm-architecture/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    2. Large Language Model Architecture
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../03-ai-platform-landscape/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    3. AI Platform Landscape
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../04-prompt-engineering/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    4. Prompt Engineering Fundamentals
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../05-custom-gpts-agents-rag/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    5. Custom GPTs, Agents, and RAG Systems
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../06-llm-api-integration/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    6. LLM API Integration
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_8" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="./" class="md-nav__link md-nav__link--active">
              
  
  <span class="md-ellipsis">
    7. Multimodal AI
  </span>
  

            </a>
            
              
              <label class="md-nav__link md-nav__link--active" for="__nav_4_8" id="__nav_4_8_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_8_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4_8">
            <span class="md-nav__icon md-icon"></span>
            7. Multimodal AI
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../quizzes/quiz-07/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quiz
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../08-governance-ethics-responsible-ai/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    8. AI Governance, Ethics, and Responsible AI
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../09-future-of-work/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    9. Future of Work and Workforce Transformation
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../10-business-applications-transformation/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    10. Business Applications and AI Transformation
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../sims/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    MicroSims
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../learning-graph/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Learning Graph
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../glossary/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Glossary
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../faq/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    FAQ
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../references/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    References
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#concepts-covered" class="md-nav__link">
    <span class="md-ellipsis">
      Concepts Covered
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#prerequisites" class="md-nav__link">
    <span class="md-ellipsis">
      Prerequisites
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#learning-objectives" class="md-nav__link">
    <span class="md-ellipsis">
      Learning Objectives
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#understanding-multimodal-ai" class="md-nav__link">
    <span class="md-ellipsis">
      Understanding Multimodal AI
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Understanding Multimodal AI">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-is-multimodal-ai" class="md-nav__link">
    <span class="md-ellipsis">
      What Is Multimodal AI?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-evolution-toward-multimodality" class="md-nav__link">
    <span class="md-ellipsis">
      The Evolution Toward Multimodality
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#image-generation" class="md-nav__link">
    <span class="md-ellipsis">
      Image Generation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Image Generation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diffusion-models-explained" class="md-nav__link">
    <span class="md-ellipsis">
      Diffusion Models Explained
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dall-e" class="md-nav__link">
    <span class="md-ellipsis">
      DALL-E
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#midjourney" class="md-nav__link">
    <span class="md-ellipsis">
      Midjourney
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stable-diffusion" class="md-nav__link">
    <span class="md-ellipsis">
      Stable Diffusion
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#image-understanding-and-vision-ai" class="md-nav__link">
    <span class="md-ellipsis">
      Image Understanding and Vision AI
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Image Understanding and Vision AI">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#vision-capabilities" class="md-nav__link">
    <span class="md-ellipsis">
      Vision Capabilities
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpt-4-vision" class="md-nav__link">
    <span class="md-ellipsis">
      GPT-4 Vision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#image-analysis-applications" class="md-nav__link">
    <span class="md-ellipsis">
      Image Analysis Applications
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#audio-ai" class="md-nav__link">
    <span class="md-ellipsis">
      Audio AI
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Audio AI">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#speech-to-text" class="md-nav__link">
    <span class="md-ellipsis">
      Speech-to-Text
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#text-to-speech" class="md-nav__link">
    <span class="md-ellipsis">
      Text-to-Speech
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#voice-cloning" class="md-nav__link">
    <span class="md-ellipsis">
      Voice Cloning
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#video-generation" class="md-nav__link">
    <span class="md-ellipsis">
      Video Generation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Video Generation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#text-to-video-technology" class="md-nav__link">
    <span class="md-ellipsis">
      Text-to-Video Technology
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sora-and-video-generation-models" class="md-nav__link">
    <span class="md-ellipsis">
      Sora and Video Generation Models
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#business-applications-of-video-ai" class="md-nav__link">
    <span class="md-ellipsis">
      Business Applications of Video AI
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#multimodal-applications-in-business" class="md-nav__link">
    <span class="md-ellipsis">
      Multimodal Applications in Business
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Multimodal Applications in Business">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#content-creation-at-scale" class="md-nav__link">
    <span class="md-ellipsis">
      Content Creation at Scale
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#accessibility-enhancement" class="md-nav__link">
    <span class="md-ellipsis">
      Accessibility Enhancement
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#customer-experience-applications" class="md-nav__link">
    <span class="md-ellipsis">
      Customer Experience Applications
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-takeaways" class="md-nav__link">
    <span class="md-ellipsis">
      Key Takeaways
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#review-questions" class="md-nav__link">
    <span class="md-ellipsis">
      Review Questions
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/Yarmoluk/Digital-Transformation-with-AI-Spring-2026/edit/main/docs/chapters/07-multimodal-ai/index.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  


<h1 id="multimodal-ai">Multimodal AI<a class="headerlink" href="#multimodal-ai" title="Permanent link">&para;</a></h1>
<h2 id="summary">Summary<a class="headerlink" href="#summary" title="Permanent link">&para;</a></h2>
<p>This chapter explores AI capabilities beyond text, including image generation, vision analysis, audio processing, and emerging video technologies. Students will learn about diffusion models, text-to-image platforms like DALL-E and Midjourney, and how to leverage multimodal capabilities for business applications. Understanding these technologies prepares students for the next wave of AI innovation.</p>
<h2 id="concepts-covered">Concepts Covered<a class="headerlink" href="#concepts-covered" title="Permanent link">&para;</a></h2>
<p>This chapter covers the following 17 concepts from the learning graph:</p>
<ol>
<li>Multimodal AI</li>
<li>Text-to-Image</li>
<li>DALL-E</li>
<li>Midjourney</li>
<li>Stable Diffusion</li>
<li>Diffusion Models</li>
<li>Image Generation</li>
<li>Image Analysis</li>
<li>Vision Capabilities</li>
<li>GPT-4 Vision</li>
<li>Text-to-Video</li>
<li>Sora</li>
<li>Audio AI</li>
<li>Speech-to-Text</li>
<li>Text-to-Speech</li>
<li>Voice Cloning</li>
<li>Multimodal Applications</li>
</ol>
<h2 id="prerequisites">Prerequisites<a class="headerlink" href="#prerequisites" title="Permanent link">&para;</a></h2>
<p>This chapter builds on concepts from:</p>
<ul>
<li><a href="../01-digital-transformation-ai-foundations/">Chapter 1: Digital Transformation and AI Foundations</a></li>
<li><a href="../03-ai-platform-landscape/">Chapter 3: AI Platform Landscape</a></li>
</ul>
<h2 id="learning-objectives">Learning Objectives<a class="headerlink" href="#learning-objectives" title="Permanent link">&para;</a></h2>
<p>After completing this chapter, students will be able to:</p>
<ul>
<li>Use text-to-image tools to generate visual content for business needs</li>
<li>Explain how diffusion models work for image generation</li>
<li>Apply vision capabilities and image analysis in applications</li>
<li>Evaluate text-to-video and audio AI technologies</li>
<li>Design multimodal content strategies for business applications</li>
</ul>
<hr />
<h2 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Permanent link">&para;</a></h2>
<p>The AI revolution extends far beyond text. <strong>Multimodal AI</strong> systems process, understand, and generate content across multiple modalities‚Äîtext, images, audio, video, and more. These capabilities transform how organizations create content, analyze visual information, and build user experiences.</p>
<p>This chapter surveys the multimodal AI landscape: image generation systems that create visuals from text descriptions, vision models that understand and analyze images, audio AI for speech processing, and emerging video generation capabilities. For business professionals, understanding these technologies opens new possibilities for marketing, product design, customer experience, and operational efficiency.</p>
<h2 id="understanding-multimodal-ai">Understanding Multimodal AI<a class="headerlink" href="#understanding-multimodal-ai" title="Permanent link">&para;</a></h2>
<h3 id="what-is-multimodal-ai">What Is Multimodal AI?<a class="headerlink" href="#what-is-multimodal-ai" title="Permanent link">&para;</a></h3>
<p><strong>Multimodal AI</strong> refers to artificial intelligence systems that can process and generate content in multiple formats‚Äîtext, images, audio, video‚Äîand often understand relationships between modalities.</p>
<p>Multimodal capabilities include:</p>
<table>
<thead>
<tr>
<th>Modality Pair</th>
<th>Direction</th>
<th>Examples</th>
</tr>
</thead>
<tbody>
<tr>
<td>Text ‚Üí Image</td>
<td>Generation</td>
<td>DALL-E, Midjourney, Stable Diffusion</td>
</tr>
<tr>
<td>Image ‚Üí Text</td>
<td>Understanding</td>
<td>GPT-4 Vision, Claude Vision</td>
</tr>
<tr>
<td>Text ‚Üí Audio</td>
<td>Generation</td>
<td>ElevenLabs, Amazon Polly</td>
</tr>
<tr>
<td>Audio ‚Üí Text</td>
<td>Understanding</td>
<td>Whisper, Google Speech-to-Text</td>
</tr>
<tr>
<td>Text ‚Üí Video</td>
<td>Generation</td>
<td>Sora, Runway, Pika</td>
</tr>
<tr>
<td>Image+Text ‚Üí Text</td>
<td>Understanding</td>
<td>Visual question answering</td>
</tr>
</tbody>
</table>
<h3 id="the-evolution-toward-multimodality">The Evolution Toward Multimodality<a class="headerlink" href="#the-evolution-toward-multimodality" title="Permanent link">&para;</a></h3>
<p>Early AI systems were unimodal‚Äîspecialized for one data type. The progression toward multimodality reflects both technical advances and recognition that human understanding is inherently multimodal.</p>
<p>Key developments:</p>
<ul>
<li><strong>2021</strong>: CLIP connects images and text in shared embedding space</li>
<li><strong>2022</strong>: DALL-E 2 and Stable Diffusion demonstrate high-quality text-to-image</li>
<li><strong>2023</strong>: GPT-4V adds vision understanding to language models</li>
<li><strong>2024</strong>: Video generation models (Sora) achieve photorealistic output</li>
<li><strong>2025</strong>: Fully integrated multimodal models become standard</li>
</ul>
<h2 id="image-generation">Image Generation<a class="headerlink" href="#image-generation" title="Permanent link">&para;</a></h2>
<h3 id="diffusion-models-explained">Diffusion Models Explained<a class="headerlink" href="#diffusion-models-explained" title="Permanent link">&para;</a></h3>
<p><strong>Diffusion models</strong> are the architecture powering modern image generation. They work by learning to reverse a gradual noising process.</p>
<p>The training process:</p>
<ol>
<li>Start with a training image</li>
<li>Progressively add random noise over many steps</li>
<li>Train the model to predict and remove noise at each step</li>
<li>Eventually, the model learns to denoise pure noise into coherent images</li>
</ol>
<p>Generation process:</p>
<ol>
<li>Start with pure random noise</li>
<li>Apply the denoising model iteratively</li>
<li>At each step, the model removes noise while incorporating the text prompt</li>
<li>After many steps, a coherent image emerges</li>
</ol>
<p>The mathematical intuition: diffusion models learn the probability distribution of images. Text conditioning biases this distribution toward images matching the description.</p>
<h4 id="diagram-diffusion-model-process">Diagram: Diffusion Model Process<a class="headerlink" href="#diagram-diffusion-model-process" title="Permanent link">&para;</a></h4>
<p>The following diagram illustrates how diffusion models generate images through iterative denoising, showing both the training process (forward diffusion) and the generation process (reverse diffusion).</p>
<pre class="mermaid"><code>flowchart LR
    subgraph Training["üéì Training: Forward Diffusion"]
        direction LR
        T1["üñºÔ∏è Original&lt;br/&gt;Image"]
        T2["üå´Ô∏è Slightly&lt;br/&gt;Noisy"]
        T3["üå´Ô∏èüå´Ô∏è More&lt;br/&gt;Noisy"]
        T4["üì∫ Pure&lt;br/&gt;Noise"]
        T1 --&gt;|"+noise"| T2 --&gt;|"+noise"| T3 --&gt;|"+noise"| T4
    end

    subgraph Generation["üé® Generation: Reverse Diffusion"]
        direction LR
        G1["üì∫ Random&lt;br/&gt;Noise"]
        G2["üå´Ô∏èüå´Ô∏è Emerging&lt;br/&gt;Structure"]
        G3["üå´Ô∏è Clearer&lt;br/&gt;Details"]
        G4["üñºÔ∏è Final&lt;br/&gt;Image"]
        G1 --&gt;|"-noise"| G2 --&gt;|"-noise"| G3 --&gt;|"-noise"| G4
    end

    PROMPT["üìù Text Prompt&lt;br/&gt;'A sunset over mountains'"]
    PROMPT -.-&gt;|"Guides each&lt;br/&gt;denoising step"| G1
    PROMPT -.-&gt; G2
    PROMPT -.-&gt; G3

    MODEL["üß† Neural Network&lt;br/&gt;Learns to predict noise"]
    T4 -.-&gt;|"Training"| MODEL
    MODEL -.-&gt;|"Inference"| G1

    style Training fill:#FFEBEE,stroke:#C62828,stroke-width:2px
    style Generation fill:#E8F5E9,stroke:#2E7D32,stroke-width:2px
    style PROMPT fill:#E3F2FD,stroke:#1565C0
    style MODEL fill:#FFF3E0,stroke:#EF6C00</code></pre>
<table>
<thead>
<tr>
<th>Process</th>
<th>Direction</th>
<th>Purpose</th>
<th>Key Action</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Forward Diffusion</strong></td>
<td>Image ‚Üí Noise</td>
<td>Training</td>
<td>Gradually add Gaussian noise over ~1000 steps</td>
</tr>
<tr>
<td><strong>Reverse Diffusion</strong></td>
<td>Noise ‚Üí Image</td>
<td>Generation</td>
<td>Iteratively predict and remove noise (~50-100 steps)</td>
</tr>
<tr>
<td><strong>Text Conditioning</strong></td>
<td>Prompt ‚Üí Image</td>
<td>Guidance</td>
<td>Bias each denoising step toward matching the description</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Why Diffusion Works</p>
<p>The model learns the statistical patterns of noise at each degradation level. During generation, it uses this knowledge to reverse the process‚Äîstarting from pure noise and gradually revealing an image that matches the conditioning prompt. Each denoising step makes small, incremental improvements guided by the text description.</p>
</div>
<h3 id="dall-e">DALL-E<a class="headerlink" href="#dall-e" title="Permanent link">&para;</a></h3>
<p><strong>DALL-E</strong> is OpenAI's text-to-image model, now in its third iteration (DALL-E 3). It generates images from natural language descriptions with remarkable understanding of concepts, styles, and composition.</p>
<p>DALL-E 3 capabilities:</p>
<ul>
<li>High-fidelity image generation</li>
<li>Understanding of complex prompts</li>
<li>Multiple artistic styles</li>
<li>Text rendering within images</li>
<li>Safety filters to prevent harmful content</li>
<li>Integrated with ChatGPT for conversational image creation</li>
</ul>
<p>Effective DALL-E prompting:</p>
<table>
<thead>
<tr>
<th>Element</th>
<th>Purpose</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>Subject</td>
<td>What to depict</td>
<td>"A golden retriever puppy"</td>
</tr>
<tr>
<td>Action</td>
<td>What's happening</td>
<td>"playing in autumn leaves"</td>
</tr>
<tr>
<td>Setting</td>
<td>Environment/context</td>
<td>"in a suburban backyard"</td>
</tr>
<tr>
<td>Style</td>
<td>Artistic approach</td>
<td>"in the style of a children's book illustration"</td>
</tr>
<tr>
<td>Mood</td>
<td>Emotional tone</td>
<td>"warm and joyful atmosphere"</td>
</tr>
<tr>
<td>Technical</td>
<td>Camera/rendering</td>
<td>"soft natural lighting, shallow depth of field"</td>
</tr>
</tbody>
</table>
<h3 id="midjourney">Midjourney<a class="headerlink" href="#midjourney" title="Permanent link">&para;</a></h3>
<p><strong>Midjourney</strong> is an independent research lab producing AI-generated images with distinctive artistic quality. Accessed primarily through Discord, Midjourney excels at creating stylized, aesthetically striking images.</p>
<p>Midjourney characteristics:</p>
<ul>
<li>Strong artistic and stylistic outputs</li>
<li>Active community with shared prompts</li>
<li>Distinctive "Midjourney look" (can be both strength and limitation)</li>
<li>Versioned models with different capabilities</li>
<li>Commercial licensing for generated images</li>
</ul>
<p>Midjourney prompt parameters:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>/imagine prompt: a cyberpunk marketplace at night, neon signs, rain-slicked streets
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>--ar 16:9 --style raw --v 6 --q 2
</span></code></pre></div>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Function</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>--ar</code></td>
<td>Aspect ratio (16:9, 4:3, 1:1, etc.)</td>
</tr>
<tr>
<td><code>--style</code></td>
<td>Aesthetic approach (raw, stylize)</td>
</tr>
<tr>
<td><code>--v</code></td>
<td>Model version</td>
</tr>
<tr>
<td><code>--q</code></td>
<td>Quality/detail level</td>
</tr>
<tr>
<td><code>--no</code></td>
<td>Negative prompt (elements to exclude)</td>
</tr>
</tbody>
</table>
<h3 id="stable-diffusion">Stable Diffusion<a class="headerlink" href="#stable-diffusion" title="Permanent link">&para;</a></h3>
<p><strong>Stable Diffusion</strong> is an open-source image generation model that can be run locally or customized extensively.</p>
<p>Advantages of open-source:</p>
<ul>
<li><strong>Local execution</strong>: Run on personal hardware (with capable GPU)</li>
<li><strong>Customization</strong>: Fine-tune on specific styles or subjects</li>
<li><strong>No usage limits</strong>: Generate unlimited images after setup</li>
<li><strong>Privacy</strong>: Images never sent to external servers</li>
<li><strong>Extensions</strong>: Community-developed plugins and modifications</li>
</ul>
<p>Business considerations:</p>
<table>
<thead>
<tr>
<th>Platform</th>
<th>Best For</th>
</tr>
</thead>
<tbody>
<tr>
<td>DALL-E 3</td>
<td>Quick generation, ChatGPT integration, safety-critical</td>
</tr>
<tr>
<td>Midjourney</td>
<td>Artistic/stylized content, creative exploration</td>
</tr>
<tr>
<td>Stable Diffusion</td>
<td>High volume, customization, privacy requirements, cost control</td>
</tr>
</tbody>
</table>
<h2 id="image-understanding-and-vision-ai">Image Understanding and Vision AI<a class="headerlink" href="#image-understanding-and-vision-ai" title="Permanent link">&para;</a></h2>
<h3 id="vision-capabilities">Vision Capabilities<a class="headerlink" href="#vision-capabilities" title="Permanent link">&para;</a></h3>
<p>Modern LLMs with <strong>vision capabilities</strong> can analyze images, answer questions about visual content, and integrate visual understanding with language processing.</p>
<p>Vision model capabilities:</p>
<ul>
<li><strong>Object identification</strong>: What objects are present in an image</li>
<li><strong>Scene understanding</strong>: Comprehending the overall context</li>
<li><strong>Text extraction (OCR)</strong>: Reading text within images</li>
<li><strong>Chart/graph interpretation</strong>: Understanding data visualizations</li>
<li><strong>Spatial reasoning</strong>: Understanding relationships between objects</li>
<li><strong>Visual question answering</strong>: Responding to questions about images</li>
</ul>
<h3 id="gpt-4-vision">GPT-4 Vision<a class="headerlink" href="#gpt-4-vision" title="Permanent link">&para;</a></h3>
<p><strong>GPT-4 Vision (GPT-4V)</strong> and subsequent models integrate vision understanding with language capabilities, enabling conversations about images.</p>
<p>Use cases:</p>
<table>
<thead>
<tr>
<th>Domain</th>
<th>Application</th>
</tr>
</thead>
<tbody>
<tr>
<td>Customer service</td>
<td>Analyze customer-submitted photos of product issues</td>
</tr>
<tr>
<td>Healthcare</td>
<td>Medical image analysis assistance (with appropriate oversight)</td>
</tr>
<tr>
<td>Retail</td>
<td>Product recognition, inventory verification</td>
</tr>
<tr>
<td>Real estate</td>
<td>Property photo analysis and description</td>
</tr>
<tr>
<td>Accessibility</td>
<td>Image description for visually impaired users</td>
</tr>
<tr>
<td>Quality control</td>
<td>Defect detection in manufacturing</td>
</tr>
</tbody>
</table>
<p>GPT-4V API usage:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4-vision-preview&quot;</span><span class="p">,</span>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a>    <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>        <span class="p">{</span>
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a>            <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a>            <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="p">[</span>
</span><span id="__span-1-7"><a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a>                <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="s2">&quot;What issues do you see in this product image?&quot;</span><span class="p">},</span>
</span><span id="__span-1-8"><a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a>                <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;image_url&quot;</span><span class="p">,</span> <span class="s2">&quot;image_url&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;url&quot;</span><span class="p">:</span> <span class="n">image_url</span><span class="p">}}</span>
</span><span id="__span-1-9"><a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a>            <span class="p">]</span>
</span><span id="__span-1-10"><a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a>        <span class="p">}</span>
</span><span id="__span-1-11"><a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a>    <span class="p">]</span>
</span><span id="__span-1-12"><a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a><span class="p">)</span>
</span></code></pre></div>
<h3 id="image-analysis-applications">Image Analysis Applications<a class="headerlink" href="#image-analysis-applications" title="Permanent link">&para;</a></h3>
<p>Practical applications of vision AI:</p>
<p><strong>Document processing</strong>:
- Extract data from invoices, receipts, forms
- Digitize handwritten notes
- Analyze contracts and agreements</p>
<p><strong>Visual search</strong>:
- Find products by image
- Identify parts or components
- Match similar items in inventory</p>
<p><strong>Content moderation</strong>:
- Detect inappropriate content
- Verify brand compliance
- Monitor user-generated images</p>
<h2 id="audio-ai">Audio AI<a class="headerlink" href="#audio-ai" title="Permanent link">&para;</a></h2>
<h3 id="speech-to-text">Speech-to-Text<a class="headerlink" href="#speech-to-text" title="Permanent link">&para;</a></h3>
<p><strong>Speech-to-text (STT)</strong> converts spoken language into written text. Modern STT systems achieve near-human accuracy across multiple languages.</p>
<p>Leading STT solutions:</p>
<table>
<thead>
<tr>
<th>Solution</th>
<th>Strengths</th>
</tr>
</thead>
<tbody>
<tr>
<td>OpenAI Whisper</td>
<td>High accuracy, multilingual, open-source</td>
</tr>
<tr>
<td>Google Speech-to-Text</td>
<td>Real-time streaming, extensive language support</td>
</tr>
<tr>
<td>Amazon Transcribe</td>
<td>AWS integration, specialized vocabularies</td>
</tr>
<tr>
<td>Azure Speech</td>
<td>Enterprise features, custom models</td>
</tr>
<tr>
<td>AssemblyAI</td>
<td>Developer-friendly, transcript analysis features</td>
</tr>
</tbody>
</table>
<p>Whisper usage example:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="kn">from</span> <span class="nn">openai</span> <span class="kn">import</span> <span class="n">OpenAI</span>
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a>
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="n">client</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">()</span>
</span><span id="__span-2-4"><a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a>
</span><span id="__span-2-5"><a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a><span class="n">audio_file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;meeting.mp3&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span>
</span><span id="__span-2-6"><a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a><span class="n">transcript</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">audio</span><span class="o">.</span><span class="n">transcriptions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
</span><span id="__span-2-7"><a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a>    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;whisper-1&quot;</span><span class="p">,</span>
</span><span id="__span-2-8"><a id="__codelineno-2-8" name="__codelineno-2-8" href="#__codelineno-2-8"></a>    <span class="n">file</span><span class="o">=</span><span class="n">audio_file</span>
</span><span id="__span-2-9"><a id="__codelineno-2-9" name="__codelineno-2-9" href="#__codelineno-2-9"></a><span class="p">)</span>
</span><span id="__span-2-10"><a id="__codelineno-2-10" name="__codelineno-2-10" href="#__codelineno-2-10"></a><span class="nb">print</span><span class="p">(</span><span class="n">transcript</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
</span></code></pre></div>
<h3 id="text-to-speech">Text-to-Speech<a class="headerlink" href="#text-to-speech" title="Permanent link">&para;</a></h3>
<p><strong>Text-to-speech (TTS)</strong> generates spoken audio from text. Modern TTS produces remarkably natural speech with appropriate prosody and emotion.</p>
<p>TTS capabilities:</p>
<ul>
<li><strong>Multiple voices</strong>: Different speakers, genders, ages</li>
<li><strong>Language support</strong>: Generate speech in various languages</li>
<li><strong>Emotion control</strong>: Adjust speaking style (happy, serious, urgent)</li>
<li><strong>SSML support</strong>: Fine control over pronunciation, pauses, emphasis</li>
<li><strong>Real-time</strong>: Low-latency generation for interactive applications</li>
</ul>
<p>Leading TTS platforms:</p>
<table>
<thead>
<tr>
<th>Platform</th>
<th>Notable Features</th>
</tr>
</thead>
<tbody>
<tr>
<td>ElevenLabs</td>
<td>Ultra-realistic voices, voice cloning</td>
</tr>
<tr>
<td>Amazon Polly</td>
<td>Many languages, SSML, neural voices</td>
</tr>
<tr>
<td>Google Cloud TTS</td>
<td>WaveNet voices, custom voice creation</td>
</tr>
<tr>
<td>Azure Speech</td>
<td>Neural TTS, custom neural voice</td>
</tr>
<tr>
<td>OpenAI TTS</td>
<td>Natural voices, simple API</td>
</tr>
</tbody>
</table>
<h3 id="voice-cloning">Voice Cloning<a class="headerlink" href="#voice-cloning" title="Permanent link">&para;</a></h3>
<p><strong>Voice cloning</strong> creates synthetic speech that mimics a specific person's voice. This technology enables personalized audio content but raises significant ethical considerations.</p>
<p>Legitimate applications:</p>
<ul>
<li>Content creators scaling audio production</li>
<li>Accessibility tools for those who've lost speech capability</li>
<li>Dubbing/localization preserving original voice characteristics</li>
<li>Virtual assistants with branded voices</li>
<li>Audiobook narration at scale</li>
</ul>
<div class="admonition warning">
<p class="admonition-title">Ethical and Legal Considerations</p>
<p>Voice cloning without consent is generally illegal and unethical. Many jurisdictions have laws against impersonation. Reputable platforms require consent verification and maintain audit trails.</p>
</div>
<h2 id="video-generation">Video Generation<a class="headerlink" href="#video-generation" title="Permanent link">&para;</a></h2>
<h3 id="text-to-video-technology">Text-to-Video Technology<a class="headerlink" href="#text-to-video-technology" title="Permanent link">&para;</a></h3>
<p><strong>Text-to-video</strong> generates video content from text descriptions. This emerging technology represents a major frontier in generative AI.</p>
<p>The technical challenge: Video generation requires temporal consistency‚Äîobjects must maintain identity across frames, motion must be coherent, and lighting must be consistent over time.</p>
<h3 id="sora-and-video-generation-models">Sora and Video Generation Models<a class="headerlink" href="#sora-and-video-generation-models" title="Permanent link">&para;</a></h3>
<p><strong>Sora</strong>, OpenAI's text-to-video model announced in 2024, demonstrated unprecedented quality in video generation.</p>
<p>Sora capabilities:</p>
<ul>
<li>Generate videos up to a minute long</li>
<li>High visual fidelity and temporal consistency</li>
<li>Complex scenes with multiple subjects</li>
<li>Understanding of physics and motion</li>
<li>Text-to-video and image-to-video</li>
</ul>
<p>Other video generation platforms:</p>
<table>
<thead>
<tr>
<th>Platform</th>
<th>Focus</th>
</tr>
</thead>
<tbody>
<tr>
<td>Runway</td>
<td>Professional creative tools, Gen-2 model</td>
</tr>
<tr>
<td>Pika</td>
<td>Short clips, stylized content</td>
</tr>
<tr>
<td>Stable Video Diffusion</td>
<td>Open-source video generation</td>
</tr>
<tr>
<td>Synthesia</td>
<td>AI avatar videos for business</td>
</tr>
<tr>
<td>HeyGen</td>
<td>AI spokesperson videos</td>
</tr>
</tbody>
</table>
<h3 id="business-applications-of-video-ai">Business Applications of Video AI<a class="headerlink" href="#business-applications-of-video-ai" title="Permanent link">&para;</a></h3>
<p>Video AI applications:</p>
<ul>
<li><strong>Marketing</strong>: Personalized video ads at scale</li>
<li><strong>Training</strong>: Custom training videos without production costs</li>
<li><strong>Product demos</strong>: Dynamic product visualization</li>
<li><strong>Social media</strong>: Content creation acceleration</li>
<li><strong>Localization</strong>: Video translation with lip sync</li>
</ul>
<h2 id="multimodal-applications-in-business">Multimodal Applications in Business<a class="headerlink" href="#multimodal-applications-in-business" title="Permanent link">&para;</a></h2>
<h3 id="content-creation-at-scale">Content Creation at Scale<a class="headerlink" href="#content-creation-at-scale" title="Permanent link">&para;</a></h3>
<p>Multimodal AI enables unprecedented content creation efficiency:</p>
<table>
<thead>
<tr>
<th>Content Type</th>
<th>Traditional Process</th>
<th>AI-Augmented</th>
</tr>
</thead>
<tbody>
<tr>
<td>Blog post with images</td>
<td>Writer + designer + stock photos</td>
<td>Writer prompts AI for custom images</td>
</tr>
<tr>
<td>Product description</td>
<td>Photographer + copywriter</td>
<td>Vision AI describes products automatically</td>
</tr>
<tr>
<td>Video tutorial</td>
<td>Scripting, recording, editing</td>
<td>AI generates from outline</td>
</tr>
<tr>
<td>Audio content</td>
<td>Recording studio, voice talent</td>
<td>TTS from scripts</td>
</tr>
</tbody>
</table>
<h3 id="accessibility-enhancement">Accessibility Enhancement<a class="headerlink" href="#accessibility-enhancement" title="Permanent link">&para;</a></h3>
<p>Multimodal AI improves accessibility:</p>
<ul>
<li><strong>Image descriptions</strong>: Auto-generate alt text for visually impaired users</li>
<li><strong>Captions</strong>: Automatic subtitles for deaf/hard-of-hearing audiences</li>
<li><strong>Audio versions</strong>: TTS creates audio from written content</li>
<li><strong>Translation</strong>: Multi-language content from single source</li>
</ul>
<h3 id="customer-experience-applications">Customer Experience Applications<a class="headerlink" href="#customer-experience-applications" title="Permanent link">&para;</a></h3>
<p>Multimodal capabilities enhance customer interactions:</p>
<ul>
<li><strong>Visual customer service</strong>: Customers share images; AI diagnoses issues</li>
<li><strong>Voice interfaces</strong>: Natural spoken interaction with AI systems</li>
<li><strong>Visual search</strong>: Find products by uploading images</li>
<li><strong>Personalized content</strong>: Dynamic image/video creation for individuals</li>
</ul>
<h2 id="key-takeaways">Key Takeaways<a class="headerlink" href="#key-takeaways" title="Permanent link">&para;</a></h2>
<ul>
<li><strong>Multimodal AI</strong> processes and generates content across text, images, audio, and video modalities</li>
<li><strong>Diffusion models</strong> power modern image generation by learning to reverse a noise-addition process</li>
<li><strong>DALL-E, Midjourney, and Stable Diffusion</strong> offer different trade-offs for text-to-image generation (integration, style, customization)</li>
<li><strong>Vision models</strong> like GPT-4V enable image understanding and analysis in business applications</li>
<li><strong>Speech-to-text</strong> (Whisper) and <strong>text-to-speech</strong> (ElevenLabs) provide high-quality audio capabilities</li>
<li><strong>Voice cloning</strong> enables personalized audio but requires ethical consideration</li>
<li><strong>Text-to-video</strong> (Sora, Runway) represents the emerging frontier of generative AI</li>
<li><strong>Business applications</strong> span content creation, accessibility, and customer experience</li>
</ul>
<hr />
<h2 id="review-questions">Review Questions<a class="headerlink" href="#review-questions" title="Permanent link">&para;</a></h2>
<details class="question">
<summary>Explain how diffusion models generate images from text prompts.</summary>
<p>Diffusion models learn to reverse a gradual noising process. During training, images are progressively corrupted with noise over many steps; the model learns to predict and remove this noise at each step. For generation, the process starts with pure random noise, and the model iteratively denoises it into a coherent image. Text conditioning works by biasing the denoising process toward images that match the text description‚Äîat each step, the model removes noise in a direction consistent with the prompt. This iterative refinement over 50-100 steps produces high-quality images matching the description.</p>
</details>
<details class="question">
<summary>Compare the trade-offs between DALL-E 3, Midjourney, and Stable Diffusion for enterprise use.</summary>
<p><strong>DALL-E 3</strong>: Best for seamless ChatGPT integration, safety-critical applications, quick generation without technical setup. Trade-offs: usage costs, less stylistic control, dependent on OpenAI infrastructure. <strong>Midjourney</strong>: Best for artistic/stylized content where aesthetic quality matters. Trade-offs: Discord-based workflow, distinctive style that may not match all needs, subscription model. <strong>Stable Diffusion</strong>: Best for high volume, privacy-sensitive applications, heavy customization, cost control. Trade-offs: requires technical setup, GPU hardware, model management; less out-of-box quality than commercial options.</p>
</details>
<details class="question">
<summary>What business applications does vision AI enable that weren't practical before?</summary>
<p>Vision AI enables: (1) <strong>Automated document processing</strong>‚Äîextract data from invoices, receipts, forms without manual entry, (2) <strong>Visual customer service</strong>‚Äîcustomers share photos; AI diagnoses product issues, (3) <strong>Automated accessibility</strong>‚Äîgenerate image descriptions for all visual content, (4) <strong>Visual quality control</strong>‚Äîdetect manufacturing defects at scale, (5) <strong>Content moderation</strong>‚Äîautomatically flag inappropriate images, (6) <strong>Visual search</strong>‚Äîcustomers find products by uploading images rather than keywords. These applications were impractical before because they required human judgment at each instance; vision AI scales this analysis.</p>
</details>







  
  



  



  <form class="md-feedback" name="feedback" hidden>
    <fieldset>
      <legend class="md-feedback__title">
        Was this page helpful?
      </legend>
      <div class="md-feedback__inner">
        <div class="md-feedback__list">
          
            <button class="md-feedback__icon md-icon" type="submit" title="This page was helpful" data-md-value="1">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 12a8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8 8 8 0 0 0 8-8m2 0a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10M10 9.5c0 .8-.7 1.5-1.5 1.5S7 10.3 7 9.5 7.7 8 8.5 8s1.5.7 1.5 1.5m7 0c0 .8-.7 1.5-1.5 1.5S14 10.3 14 9.5 14.7 8 15.5 8s1.5.7 1.5 1.5m-5 7.73c-1.75 0-3.29-.73-4.19-1.81L9.23 14c.45.72 1.52 1.23 2.77 1.23s2.32-.51 2.77-1.23l1.42 1.42c-.9 1.08-2.44 1.81-4.19 1.81"/></svg>
            </button>
          
            <button class="md-feedback__icon md-icon" type="submit" title="This page could be improved" data-md-value="0">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 12a8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8 8 8 0 0 0 8-8m2 0a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10m-6.5-4c.8 0 1.5.7 1.5 1.5s-.7 1.5-1.5 1.5-1.5-.7-1.5-1.5.7-1.5 1.5-1.5M10 9.5c0 .8-.7 1.5-1.5 1.5S7 10.3 7 9.5 7.7 8 8.5 8s1.5.7 1.5 1.5m2 4.5c1.75 0 3.29.72 4.19 1.81l-1.42 1.42C14.32 16.5 13.25 16 12 16s-2.32.5-2.77 1.23l-1.42-1.42C8.71 14.72 10.25 14 12 14"/></svg>
            </button>
          
        </div>
        <div class="md-feedback__note">
          
            <div data-md-value="1" hidden>
              
              
                
              
              Thanks for your feedback!
            </div>
          
            <div data-md-value="0" hidden>
              
              
                
              
              Thanks for your feedback!
            </div>
          
        </div>
      </div>
    </fieldset>
  </form>


                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../../quizzes/quiz-06/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Quiz">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Quiz
              </div>
            </div>
          </a>
        
        
          
          <a href="../../quizzes/quiz-07/" class="md-footer__link md-footer__link--next" aria-label="Next: Quiz">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Quiz
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2026 Daniel Yarmoluk | All rights reserved.
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/Yarmoluk/Digital-Transformation-with-AI-Spring-2026" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://linkedin.com" target="_blank" rel="noopener" title="linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5m282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["content.code.copy", "navigation.expand", "navigation.path", "navigation.prune", "navigation.indexes", "toc.follow", "navigation.top", "navigation.footer", "content.action.edit"], "search": "../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.83f73b43.min.js"></script>
      
    
  </body>
</html>